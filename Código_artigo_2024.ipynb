{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nw-Aenn0phW"
      },
      "source": [
        "Código para o projeto/artigo mestrado - 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xDiUvJo1bLM"
      },
      "source": [
        "Instalando bibiotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWyFOn5D1Zib",
        "outputId": "d8ce5535-197f-4901-f6f7-b4d3ea73e7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (2.16.1)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\intel\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
            "Requirement already satisfied: optree in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: tensorboardX in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboardX) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboardX) (4.25.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (2.2.2+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.17.2+cu118)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (2.2.2+cu118)\n",
            "Requirement already satisfied: filelock in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: timm in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.9.16)\n",
            "Requirement already satisfied: torch in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from timm) (2.2.2+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from timm) (0.17.2+cu118)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from timm) (0.22.1)\n",
            "Requirement already satisfied: safetensors in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from huggingface_hub->timm) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from huggingface_hub->timm) (2024.3.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: requests in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from huggingface_hub->timm) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch->timm) (3.1.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchvision->timm) (10.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from requests->huggingface_hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pillow in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (10.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: cjm_pandas_utils in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.0.3)\n",
            "Requirement already satisfied: cjm_pil_utils in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.0.9)\n",
            "Requirement already satisfied: cjm_pytorch_utils in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.0.6)\n",
            "Requirement already satisfied: cjm_torchvision_tfms in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.0.11)\n",
            "Requirement already satisfied: torchtnt in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.2.3)\n",
            "Requirement already satisfied: torcheval in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.0.7)\n",
            "Requirement already satisfied: pandas in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from cjm_pandas_utils) (2.2.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from cjm_pil_utils) (1.26.4)\n",
            "Requirement already satisfied: pillow in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from cjm_pil_utils) (10.2.0)\n",
            "Requirement already satisfied: torch in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from cjm_pytorch_utils) (2.2.2+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from cjm_pytorch_utils) (0.17.2+cu118)\n",
            "Requirement already satisfied: cjm-psl-utils in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from cjm_torchvision_tfms) (0.0.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (2024.3.1)\n",
            "Requirement already satisfied: tensorboard in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (2.16.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (24.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (5.9.8)\n",
            "Requirement already satisfied: pyre-extensions in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (0.0.30)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (4.10.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (69.2.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (4.66.2)\n",
            "Requirement already satisfied: tabulate in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchtnt) (0.9.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch->cjm_pytorch_utils) (3.13.3)\n",
            "Requirement already satisfied: sympy in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch->cjm_pytorch_utils) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch->cjm_pytorch_utils) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch->cjm_pytorch_utils) (3.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from pandas->cjm_pandas_utils) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from pandas->cjm_pandas_utils) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from pandas->cjm_pandas_utils) (2024.1)\n",
            "Requirement already satisfied: typing-inspect in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from pyre-extensions->torchtnt) (0.9.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard->torchtnt) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard->torchtnt) (1.62.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard->torchtnt) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard->torchtnt) (4.25.3)\n",
            "Requirement already satisfied: six>1.9 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard->torchtnt) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard->torchtnt) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tensorboard->torchtnt) (3.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from tqdm->torchtnt) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->torchtnt) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from sympy->torch->cjm_pytorch_utils) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from typing-inspect->pyre-extensions->torchtnt) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torchmetrics in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (1.3.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchmetrics) (2.2.2+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torchmetrics) (0.11.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.2.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.3)\n",
            "Requirement already satisfied: sympy in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (3.8.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib) (2.9.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: seaborn in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from seaborn) (2.2.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from seaborn) (3.8.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\intel\\anaconda3\\envs\\mestradodouglas\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow\n",
        "%pip install tensorboardX\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install timm\n",
        "%pip install pillow\n",
        "%pip install cjm_pandas_utils cjm_pil_utils cjm_pytorch_utils cjm_torchvision_tfms torchtnt torcheval\n",
        "%pip install torchmetrics\n",
        "%pip install matplotlib\n",
        "%pip install seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MicqcgAEG34"
      },
      "source": [
        "Importando dependências necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xUOu7wjhEJRo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\intel\\Anaconda3\\envs\\mestradodouglas\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Import Python Standard Library dependencies\n",
        "#from copy import copy\n",
        "#import datetime\n",
        "#from glob import glob\n",
        "import json\n",
        "import math\n",
        "#import multiprocessing\n",
        "import os\n",
        "from pathlib import Path\n",
        "#import random\n",
        "#import urllib.request\n",
        "import timm\n",
        "import csv\n",
        "from utils.tools import del_file\n",
        "\n",
        "# Import utility functions\n",
        "#from cjm_pandas_utils.core import markdown_to_pandas\n",
        "from cjm_pil_utils.core import get_img_files\n",
        "#from cjm_psl_utils.core import download_file, file_extract\n",
        "from cjm_pytorch_utils.core import set_seed, get_torch_device\n",
        "#from cjm_torchvision_tfms.core import ResizeMax, PadSquare\n",
        "\n",
        "# Import matplotlib for creating plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Import pandas module for data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Do not truncate the contents of cells and display all rows and columns\n",
        "pd.set_option('max_colwidth', None, 'display.max_rows', None, 'display.max_columns', None)\n",
        "\n",
        "# Import PIL for image manipulation\n",
        "from PIL import Image\n",
        "\n",
        "# Import timm library\n",
        "import timm\n",
        "\n",
        "# Import PyTorch dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.amp import autocast\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "torchvision.disable_beta_transforms_warning()\n",
        "import torchvision.transforms.v2  as transforms\n",
        "#from torchvision.transforms.v2 import functional as TF\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "#from torchtnt.utils import get_module_summary\n",
        "from torcheval.metrics import MulticlassAccuracy\n",
        "#from torch import tensor\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9pDf6KewAr3",
        "outputId": "413df00c-59c5-4c6f-b808-52aecdc372d7"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6yDBCPF_Vs4"
      },
      "source": [
        "Defining the class for training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "rUxkKGOC0yB5",
        "outputId": "d0e080d9-f054-4d4f-bc0a-ca6b803c6aa4"
      },
      "outputs": [],
      "source": [
        "class training_class_models():\n",
        "    def __init__(self,program_path,image_path_train,image_path_val,image_path_test,\\\n",
        "        model_name,lr,epochs,img_size):\n",
        "        self.seed = 1234\n",
        "        set_seed(self.seed)\n",
        "        torch.cuda.set_device(1)\n",
        "        self.device = get_torch_device()        \n",
        "        self.dtype = torch.float32        \n",
        "        self.model_name = model_name\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.img_size = img_size        \n",
        "        print(f\"device is:{self.device}\")        \n",
        "\n",
        "        self.program_path = Path(program_path)\n",
        "        self.image_path_train = Path(image_path_train)\n",
        "        self.image_path_val = Path(image_path_val)\n",
        "        self.image_path_test = Path(image_path_test)                \n",
        "                \n",
        "        #tensorboard configuration        \n",
        "        self.writer = SummaryWriter(f\"runs/{model_name}\")\n",
        "    \n",
        "    def show_images_stats(self):\n",
        "        \n",
        "        img_folder_paths_train = [folder_train for folder_train in self.image_path_train.iterdir() if folder_train.is_dir()]\n",
        "        img_folder_paths_val = [folder_val for folder_val in self.image_path_val.iterdir() if folder_val.is_dir()]\n",
        "\n",
        "        # Get a list of all image file paths from the image folders\n",
        "        class_file_paths_train = [get_img_files(folder) for folder in img_folder_paths_train]\n",
        "        class_file_paths_val = [get_img_files(folder) for folder in img_folder_paths_val]\n",
        "\n",
        "        # Get the number of samples for each image class\n",
        "        class_counts_dict_train = {folder[0].parent.name:len(folder) for folder in class_file_paths_train}\n",
        "        class_counts_dict_val = {folder[0].parent.name:len(folder) for folder in class_file_paths_val}\n",
        "\n",
        "        # Get all image files in the 'img_dir' directory\n",
        "        img_paths_train = [\n",
        "            file\n",
        "            for folder in class_file_paths_train # Iterate through each image folder\n",
        "            for file in folder # Get a list of image files in each image folder\n",
        "        ]\n",
        "        \n",
        "        # Get all image files in the 'img_dir' directory\n",
        "        img_paths_val = [\n",
        "            file\n",
        "            for folder in class_file_paths_val # Iterate through each image folder\n",
        "            for file in folder # Get a list of image files in each image folder\n",
        "        ]\n",
        "        \n",
        "        ordered_classes_names = [\n",
        "            os.path.basename(folder)\n",
        "            for folder in self.image_path_train.iterdir() if folder.is_dir()\n",
        "        ]    \n",
        "\n",
        "        index = [\n",
        "            i for i in range(0,len(ordered_classes_names))\n",
        "        ]\n",
        "        \n",
        "        #create the mapping from the labels in train directory\n",
        "        self.labels_map = dict(zip(index,ordered_classes_names))\n",
        "\n",
        "        # Print the number of image files\n",
        "        print(f\"Number of train Images: {len(img_paths_train)}\")\n",
        "        \n",
        "        # Print the number of image files\n",
        "        print(f\"Number of val Images: {len(img_paths_val)}\")\n",
        "        \n",
        "        # Get a list of unique labels\n",
        "        self.class_names = list(class_counts_dict_train.keys())\n",
        "\n",
        "        # Display the labels and the corresponding number of samples using a Pandas DataFrame\n",
        "        class_counts_train = pd.DataFrame.from_dict({'Count':class_counts_dict_train})        \n",
        "    \n",
        "        # Display the labels and the corresponding number of samples using a Pandas DataFrame\n",
        "        class_counts_val = pd.DataFrame.from_dict({'Count':class_counts_dict_val})\n",
        "        return class_counts_dict_train, class_counts_dict_val\n",
        "    \n",
        "    def data_preprocessing(self):\n",
        "        self.dataset_name = 'rockdataset'\n",
        "        \n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomRotation((0, 180)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.CenterCrop(700),  # center area for classification\n",
        "            transforms.Resize([self.img_size, self.img_size]),\n",
        "            transforms.ColorJitter(brightness=0.15, contrast=0.3, saturation=0.3, hue=0.06),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        val_transforms = transforms.Compose([    \n",
        "            transforms.CenterCrop(700),  # center area for classification\n",
        "            transforms.Resize([self.img_size, self.img_size]),    \n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "        train_data = datasets.ImageFolder(self.image_path_train,transform=train_transforms)\n",
        "        val_data = datasets.ImageFolder(self.image_path_val,transform=val_transforms)\n",
        "        test_data = datasets.ImageFolder(self.image_path_test,transform=val_transforms)\n",
        "        \n",
        "        # self.labels_map = {\n",
        "        #     0:  \"granite-blackswan\",            \n",
        "        #     1:  \"marble-shadow\",            \n",
        "        #     2:  \"quartzite-oceanblue\",\n",
        "        #     3:  \"quartzite-patagonia\"            \n",
        "        # }\n",
        "        \n",
        "        # self.labels_map = {\n",
        "        #     0:  \"granite-blackswan\",\n",
        "        #     1:  \"granite-lucyinthesky\",\n",
        "        #     2:  \"granite-nevascawhite\",\n",
        "        #     3:  \"marble-dolomite-brancoparana\",\n",
        "        #     4:  \"marble-dolomite-calacata\",\n",
        "        #     5:  \"marble-shadow\",\n",
        "        #     6:  \"quartzite-biancosuperiore\",\n",
        "        #     7:  \"quartzite-oceanblue\",\n",
        "        #     8:  \"quartzite-patagonia\",\n",
        "        #     9:  \"quartzite-silvermoon\",\n",
        "        #     10: \"quartzite-tajmahal\",\n",
        "        #     11: \"quartzite-volupia\"\n",
        "        # } \n",
        "        \n",
        "        self.train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "        self.val_dataloader = DataLoader(val_data, batch_size=32)\n",
        "        self.test_dataloader = DataLoader(test_data, batch_size=32)        \n",
        "\n",
        "    def load_pretrained_model(self):\n",
        "        \n",
        "        if (self.model_name[0:6] == 'ResNet'):\n",
        "            if(self.model_name == \"ResNet50\"):\n",
        "                self.model = models.resnet50(pretrained=True)\n",
        "            elif(self.model_name == \"ResNet101\"):\n",
        "                self.model = models.resnet101(pretrained=True)\n",
        "            num_ftrs = self.model.fc.in_features\n",
        "            self.model.fc = nn.Linear(num_ftrs, len(self.labels_map))                \n",
        "        else:\n",
        "            self.model = timm.create_model(self.model_name, pretrained=True, num_classes=len(self.labels_map))\n",
        "\n",
        "        # Set the device and data type for the model\n",
        "        self.model = self.model.to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "        # Add attributes to store the device and model name for later reference\n",
        "        self.model.device = self.device\n",
        "        self.model.name = self.model_name\n",
        "        print(f\"model {self.model_name} loaded\")\n",
        "    \n",
        "    def makedir_to_save_model(self):        \n",
        "        # Create a directory to store the checkpoints if it does not already exist\n",
        "        checkpoint_dir = self.program_path/f\"models/{self.model_name}\"        \n",
        "\n",
        "        # Create the checkpoint directory if it does not already exist\n",
        "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # The model checkpoint path\n",
        "        self.checkpoint_path = checkpoint_dir/f\"{self.model_name}.pth\"\n",
        "\n",
        "        # Set file path\n",
        "        class_labels_path = checkpoint_dir/f\"{self.dataset_name}-classes.json\"\n",
        "\n",
        "        # Save class labels in JSON format\n",
        "        with open(class_labels_path, \"w\") as write_file:\n",
        "            json.dump(self.labels_map, write_file)        \n",
        "    \n",
        "    def train_and_val(self):\n",
        "        \n",
        "        # Function to run a single training/validation epoch\n",
        "        def run_epoch(model, dataloader, optimizer, metric, lr_scheduler, device, scaler, epoch_id, is_training):\n",
        "            # Set model to training mode if 'is_training' is True, else set to evaluation mode\n",
        "            model.train() if is_training else model.eval()\n",
        "\n",
        "            # Reset the performance metric\n",
        "            metric.reset()\n",
        "            # Initialize the average loss for the current epoch\n",
        "            epoch_loss = 0\n",
        "            # Initialize progress bar with total number of batches in the dataloader\n",
        "            progress_bar = tqdm(total=len(dataloader), desc=\"Train\" if is_training else \"Eval\")\n",
        "\n",
        "            # Iterate over data batches\n",
        "            for batch_id, (inputs, targets) in enumerate(dataloader):\n",
        "                # Move inputs and targets to the specified device (e.g., GPU)\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                # Enables gradient calculation if 'is_training' is True\n",
        "                with torch.set_grad_enabled(is_training):\n",
        "                    # Automatic Mixed Precision (AMP) context manager for improved performance\n",
        "                    with autocast(torch.device(device).type):\n",
        "                        outputs = model(inputs) # Forward pass\n",
        "                        loss = torch.nn.functional.cross_entropy(outputs, targets) # Compute loss\n",
        "\n",
        "                # Update the performance metric\n",
        "                metric.update(outputs.detach().cpu(), targets.detach().cpu())\n",
        "\n",
        "                # If in training mode\n",
        "                if is_training:\n",
        "                    if scaler:\n",
        "                        scaler.scale(loss).backward()\n",
        "                        scaler.step(optimizer)\n",
        "                        old_scaler = scaler.get_scale()\n",
        "                        scaler.update()\n",
        "                        new_scaler = scaler.get_scale()\n",
        "                        if new_scaler >= old_scaler:\n",
        "                            lr_scheduler.step()\n",
        "                    else:\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        lr_scheduler.step()\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                loss_item = loss.item()\n",
        "                epoch_loss += loss_item\n",
        "                \n",
        "                # Update progress bar\n",
        "                progress_bar.set_postfix(accuracy=metric.compute().item(),\n",
        "                                        loss=loss_item,\n",
        "                                        avg_loss=epoch_loss/(batch_id+1),\n",
        "                                        lr=lr_scheduler.get_last_lr()[0] if is_training else \"\")\n",
        "                progress_bar.update()\n",
        "\n",
        "                # If loss is NaN or infinity, stop training\n",
        "                if is_training:\n",
        "                    stop_training_message = f\"Loss is NaN or infinite at epoch {epoch_id}, batch {batch_id}. Stopping training.\"\n",
        "                    assert not math.isnan(loss_item) and math.isfinite(loss_item), stop_training_message\n",
        "            \n",
        "            #write in tensorboard\n",
        "            if self.writer is not None:                \n",
        "                if(is_training):\n",
        "                    self.writer.add_scalar(\"Train/loss\",float(epoch_loss),epoch_id + 1)\n",
        "                    self.writer.add_scalar(\"Train/ACC\",float(metric.compute().item()),epoch_id + 1)\n",
        "                else:\n",
        "                    self.writer.add_scalar(\"Val/loss\",float(epoch_loss),epoch_id + 1)\n",
        "                    self.writer.add_scalar(\"Val/ACC\",float(metric.compute().item()),epoch_id + 1)\n",
        "            \n",
        "            progress_bar.close()\n",
        "            if self.writer is not None:                \n",
        "                self.writer.close()\n",
        "            \n",
        "            return epoch_loss / (batch_id + 1)\n",
        "        \n",
        "        def optimizer_lr_scheduler_metrics():\n",
        "            # AdamW optimizer; includes weight decay for regularization\n",
        "            optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, eps=1e-3)\n",
        "\n",
        "            # Learning rate scheduler; adjusts the learning rate during training\n",
        "            lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
        "                                                            max_lr=self.lr,\n",
        "                                                            total_steps=self.epochs*len(self.train_dataloader))\n",
        "\n",
        "            # Performance metric: Multiclass Accuracy\n",
        "            metric = MulticlassAccuracy()\n",
        "            \n",
        "            return optimizer, lr_scheduler, metric\n",
        "        \n",
        "        def train_loop(model, train_dataloader, valid_dataloader, optimizer, metric, lr_scheduler, device, epochs, checkpoint_path, use_scaler=False):\n",
        "            # Initialize a gradient scaler for mixed-precision training if the device is a CUDA GPU\n",
        "            scaler = GradScaler() if device.type == 'cuda' and use_scaler else None\n",
        "            best_loss = float('inf')\n",
        "\n",
        "            # Iterate over each epoch\n",
        "            for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "                # Run training epoch and compute training loss\n",
        "                train_loss = run_epoch(model, train_dataloader, optimizer, metric, lr_scheduler, device, scaler, epoch, is_training=True)\n",
        "                # Run validation epoch and compute validation loss\n",
        "                with torch.no_grad():\n",
        "                    valid_loss = run_epoch(model, valid_dataloader, None, metric, None, device, scaler, epoch, is_training=False)\n",
        "\n",
        "                # If current validation loss is lower than the best one so far, save model and update best loss\n",
        "                if valid_loss < best_loss:\n",
        "                    best_loss = valid_loss\n",
        "                    metric_value = metric.compute().item()\n",
        "                    torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "                    training_metadata = {\n",
        "                        'epoch': epoch,\n",
        "                        'train_loss': train_loss,\n",
        "                        'valid_loss': valid_loss,\n",
        "                        'metric_value': metric_value,\n",
        "                        'learning_rate': lr_scheduler.get_last_lr()[0],\n",
        "                        'model_architecture': model.name\n",
        "                    }\n",
        "\n",
        "                    # Save best_loss and metric_value in a JSON file\n",
        "                    with open(Path(checkpoint_path.parent/'training_metadata.json'), 'w') as f:\n",
        "                        json.dump(training_metadata, f)\n",
        "                    \n",
        "                    \n",
        "\n",
        "            # If the device is a GPU, empty the cache\n",
        "            #if device.type != 'cpu':\n",
        "            if str(device) != 'cpu':\n",
        "                getattr(torch, device.type).empty_cache()\n",
        "                print(f\"memory released in device {device}\")\n",
        "        \n",
        "        optimizer, lr_scheduler, metric = optimizer_lr_scheduler_metrics()\n",
        "        \n",
        "        train_loop(model=self.model,\n",
        "           train_dataloader=self.train_dataloader,\n",
        "           valid_dataloader=self.val_dataloader,\n",
        "           optimizer=optimizer,\n",
        "           metric=metric,\n",
        "           lr_scheduler=lr_scheduler,\n",
        "           device=torch.device(self.device),\n",
        "           epochs=self.epochs,\n",
        "           checkpoint_path=self.checkpoint_path,\n",
        "           use_scaler=True)\n",
        "        \n",
        "    def test_model(self,saved_model=False):                \n",
        "        \n",
        "        checkpoint_dir = self.program_path/f\"models/{self.model_name}\"\n",
        "        checkpoint_path = checkpoint_dir/f\"{self.model_name}.pth\"\n",
        "            \n",
        "        def load_model_and_test():                                    \n",
        "            if(saved_model):    \n",
        "                self.model.load_state_dict(torch.load(checkpoint_path))\n",
        "            self.model.eval()\n",
        "            \n",
        "            all_inputs = torch.empty((0, 3, self.img_size, self.img_size), dtype=torch.float32).to(self.device)\n",
        "            all_preds = torch.empty((0, len(self.labels_map)), dtype=torch.float32).to(self.device)\n",
        "            all_targets = torch.empty((0), dtype=torch.float32).to(self.device)\n",
        "                        \n",
        "            with torch.no_grad():\n",
        "                # Iterate over test data\n",
        "                for batch_id, (inputs, targets) in enumerate(self.test_dataloader):\n",
        "                    # Move inputs and targets to the specified device (e.g., GPU)\n",
        "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "                    preds = self.model(inputs)                    \n",
        "                    all_preds = torch.cat((all_preds,preds))\n",
        "                    all_inputs = torch.cat((all_inputs,inputs))\n",
        "                    all_targets = torch.cat((all_targets,targets))                            \n",
        "            \n",
        "            #if torch.device(self.device) != 'cpu':\n",
        "            if str(self.device) != 'cpu':\n",
        "                getattr(torch, self.device).empty_cache()\n",
        "                print(f\"memory released in device {self.device} - test phase\")\n",
        "            \n",
        "            \n",
        "            return all_inputs, all_targets, all_preds\n",
        "        \n",
        "        def compute_metrics(inputs, targets, preds):\n",
        "            from torchmetrics.classification import MulticlassConfusionMatrix\n",
        "            from torchmetrics.classification import MulticlassAccuracy\n",
        "            from torchmetrics.classification import MulticlassF1Score\n",
        "            import seaborn as sns\n",
        "            \n",
        "            inputs = inputs.detach().cpu() \n",
        "            targets = targets.detach().cpu()\n",
        "            preds = preds.detach().cpu()\n",
        "            metric = MulticlassConfusionMatrix(len(self.labels_map))\n",
        "            cm = metric(preds, targets)            \n",
        "            acc = MulticlassAccuracy(len(self.labels_map))\n",
        "            acc(preds, targets)\n",
        "            acc = acc.compute().item()            \n",
        "            f1score = MulticlassF1Score(len(self.labels_map))\n",
        "            f1score(preds, targets)\n",
        "            f1score = f1score.compute().item()\n",
        "            \n",
        "            figurecm = plt.figure(figsize=(6,6))\n",
        "            sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "            plt.ylabel('Actual label');\n",
        "            plt.xlabel('Predicted label');            \n",
        "            all_sample_title = 'Confusion Matrix - '+self.model_name+ '\\n acc: %.6f' % (acc)+' F1: %.6f' % (f1score)\n",
        "            plt.title(all_sample_title, size = 9);\n",
        "            figurecm.savefig(Path(checkpoint_path.parent/'confusionmatrix.jpg'))\n",
        "                        \n",
        "            preds_target = torch.argmax(preds, dim=1)\n",
        "            \n",
        "            idx = np.arange(len(preds_target))\n",
        "            err = idx[preds_target != targets]            \n",
        "            #print(err)\n",
        "            if(len(err)>5):\n",
        "                total = 5\n",
        "            else:\n",
        "                total = len(err)\n",
        "            \n",
        "            X_err = inputs[err][0:total]\n",
        "            y_err = targets[err][0:total]\n",
        "            p_err = preds_target[err][0:total]            \n",
        "            \n",
        "            figure_show_erros = plt.figure(figsize=(8,3))\n",
        "            plt.title(\"Sample Prediction erros - \"+self.model_name)\n",
        "            plt.axis(\"off\")          \n",
        "            for index, (image, label, pred) in enumerate(zip(X_err, y_err, p_err)):\n",
        "                plt.subplot(1, len(p_err), index + 1)\n",
        "                plt.imshow(image.squeeze().permute(1, 2, 0), cmap=\"gray\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f'ERROR (T|P) \\n T: %s \\n P: %s' % (self.labels_map[label.item()], self.labels_map[pred.item()]), fontsize = 6)\n",
        "            plt.show()\n",
        "            figure_show_erros.savefig(Path(checkpoint_path.parent/'sample-pred-errors.jpg'))\n",
        "            plt.close(figure_show_erros)\n",
        "            \n",
        "            save_data_test(acc,f1score)\n",
        "        \n",
        "        def save_data_test(test_acc, test_f1score):\n",
        "            row = [self.model_name, test_acc, test_f1score]\n",
        "    \n",
        "            with open('./metrics.csv', 'a',encoding='UTF8', newline='') as f:        \n",
        "                writercsv = csv.writer(f)\n",
        "                writercsv.writerow(row)\n",
        "                f.close()\n",
        "                \n",
        "        inputs, targets, preds = load_model_and_test()\n",
        "        compute_metrics(inputs, targets, preds)\n",
        "        \n",
        "\n",
        "    def initiate(self):\n",
        "       self.show_images_stats();\n",
        "       self.data_preprocessing();\n",
        "       self.load_pretrained_model();\n",
        "       self.makedir_to_save_model();\n",
        "       self.train_and_val();\n",
        "       self.test_model();\n",
        "    \n",
        "    def test_with_saved_model(self):\n",
        "        is_saved_model = True\n",
        "        self.data_preprocessing()\n",
        "        self.load_pretrained_model()        \n",
        "        self.test_model(is_saved_model)   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device is:cuda\n",
            "Number of train Images: 24263\n",
            "Number of val Images: 5214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\intel\\Anaconda3\\envs\\mestradodouglas\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model vit_base_patch16_384 loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   0%|          | 0/30 [00:00<?, ?it/s]c:\\Users\\intel\\Anaconda3\\envs\\mestradodouglas\\lib\\site-packages\\timm\\models\\vision_transformer.py:91: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  x = F.scaled_dot_product_attention(\n",
            "Train: 100%|██████████| 759/759 [41:12<00:00,  3.26s/it, accuracy=0.604, avg_loss=1.72, loss=1.58, lr=6.87e-7]\n",
            "Eval: 100%|██████████| 163/163 [02:51<00:00,  1.05s/it, accuracy=0.84, avg_loss=0.647, loss=1.18, lr=]\n",
            "Train: 100%|██████████| 759/759 [45:20<00:00,  3.58s/it, accuracy=0.952, avg_loss=0.238, loss=0.0095, lr=1.52e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:50<00:00,  1.05s/it, accuracy=0.964, avg_loss=0.148, loss=0.073, lr=]\n",
            "Train: 100%|██████████| 759/759 [39:24<00:00,  3.12s/it, accuracy=0.992, avg_loss=0.0451, loss=0.0814, lr=2.79e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:42<00:00,  1.00it/s, accuracy=0.984, avg_loss=0.0615, loss=0.0108, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:25<00:00,  2.72s/it, accuracy=0.995, avg_loss=0.0214, loss=0.000316, lr=4.36e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:45<00:00,  1.02s/it, accuracy=0.986, avg_loss=0.0476, loss=0.00549, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:52<00:00,  2.76s/it, accuracy=0.996, avg_loss=0.0156, loss=0.00113, lr=6.03e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:46<00:00,  1.02s/it, accuracy=0.991, avg_loss=0.0363, loss=0.00289, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:58<00:00,  2.76s/it, accuracy=0.997, avg_loss=0.0119, loss=0.000829, lr=7.59e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:47<00:00,  1.03s/it, accuracy=0.99, avg_loss=0.0337, loss=0.00187, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:57<00:00,  2.76s/it, accuracy=0.997, avg_loss=0.0114, loss=0.00124, lr=8.87e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:46<00:00,  1.02s/it, accuracy=0.972, avg_loss=0.0806, loss=0.00141, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:43<00:00,  2.75s/it, accuracy=0.996, avg_loss=0.0161, loss=0.000729, lr=9.71e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:42<00:00,  1.00it/s, accuracy=0.989, avg_loss=0.0362, loss=0.00116, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:16<00:00,  2.71s/it, accuracy=0.998, avg_loss=0.00757, loss=0.00119, lr=1e-5]\n",
            "Eval: 100%|██████████| 163/163 [02:45<00:00,  1.02s/it, accuracy=0.985, avg_loss=0.0444, loss=0.000656, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:49<00:00,  2.75s/it, accuracy=0.998, avg_loss=0.00776, loss=0.000387, lr=9.94e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:45<00:00,  1.02s/it, accuracy=0.991, avg_loss=0.0322, loss=0.000545, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:38<00:00,  2.74s/it, accuracy=0.998, avg_loss=0.00837, loss=6e-5, lr=9.78e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:41<00:00,  1.01it/s, accuracy=0.991, avg_loss=0.0334, loss=0.000322, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:41<00:00,  2.66s/it, accuracy=0.999, avg_loss=0.00379, loss=4.47e-5, lr=9.51e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:39<00:00,  1.02it/s, accuracy=0.988, avg_loss=0.0332, loss=0.000209, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:48<00:00,  2.67s/it, accuracy=0.999, avg_loss=0.00511, loss=0.000421, lr=9.13e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:40<00:00,  1.02it/s, accuracy=0.99, avg_loss=0.0336, loss=0.000375, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:31<00:00,  2.65s/it, accuracy=1, avg_loss=0.00107, loss=2.78e-5, lr=8.67e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:39<00:00,  1.02it/s, accuracy=0.992, avg_loss=0.0242, loss=0.000212, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:50<00:00,  2.68s/it, accuracy=0.999, avg_loss=0.00334, loss=0.000124, lr=8.12e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:41<00:00,  1.01it/s, accuracy=0.988, avg_loss=0.0365, loss=0.000715, lr=]\n",
            "Train: 100%|██████████| 759/759 [34:05<00:00,  2.70s/it, accuracy=0.999, avg_loss=0.00312, loss=0.000128, lr=7.51e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:49<00:00,  1.04s/it, accuracy=0.988, avg_loss=0.0319, loss=0.000346, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:27<00:00,  2.64s/it, accuracy=0.999, avg_loss=0.00243, loss=0.012, lr=6.83e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.987, avg_loss=0.0386, loss=9.98e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:03<00:00,  2.61s/it, accuracy=1, avg_loss=0.000963, loss=0.000685, lr=6.12e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.987, avg_loss=0.0417, loss=8.19e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:06<00:00,  2.62s/it, accuracy=1, avg_loss=0.000242, loss=2.3e-5, lr=5.38e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.986, avg_loss=0.044, loss=6.31e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:04<00:00,  2.62s/it, accuracy=1, avg_loss=0.000667, loss=4.38e-5, lr=4.63e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.986, avg_loss=0.0406, loss=6.49e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:07<00:00,  2.62s/it, accuracy=1, avg_loss=0.000341, loss=0.000359, lr=3.89e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:37<00:00,  1.03it/s, accuracy=0.986, avg_loss=0.0389, loss=6.46e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:07<00:00,  2.62s/it, accuracy=1, avg_loss=0.0002, loss=1.8e-5, lr=3.18e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.988, avg_loss=0.0337, loss=6.09e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:06<00:00,  2.62s/it, accuracy=1, avg_loss=0.000116, loss=3.36e-5, lr=2.51e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.989, avg_loss=0.0306, loss=5.69e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:07<00:00,  2.62s/it, accuracy=1, avg_loss=6.72e-5, loss=1.83e-5, lr=1.89e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.988, avg_loss=0.0308, loss=5.24e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:07<00:00,  2.62s/it, accuracy=1, avg_loss=0.000242, loss=6.32e-5, lr=1.34e-6]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.988, avg_loss=0.0337, loss=5.05e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:06<00:00,  2.62s/it, accuracy=1, avg_loss=0.00018, loss=0.000146, lr=8.73e-7]\n",
            "Eval: 100%|██████████| 163/163 [02:39<00:00,  1.03it/s, accuracy=0.987, avg_loss=0.0341, loss=4.84e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:04<00:00,  2.61s/it, accuracy=1, avg_loss=6.12e-5, loss=6.47e-6, lr=4.99e-7]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.987, avg_loss=0.0343, loss=4.66e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:11<00:00,  2.62s/it, accuracy=1, avg_loss=7.22e-5, loss=1.3e-5, lr=2.25e-7]\n",
            "Eval: 100%|██████████| 163/163 [02:39<00:00,  1.03it/s, accuracy=0.988, avg_loss=0.0338, loss=4.66e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:02<00:00,  2.61s/it, accuracy=1, avg_loss=7.48e-5, loss=8.99e-6, lr=5.71e-8]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.988, avg_loss=0.0337, loss=4.66e-5, lr=]\n",
            "Train: 100%|██████████| 759/759 [33:06<00:00,  2.62s/it, accuracy=1, avg_loss=9.65e-5, loss=2.46e-5, lr=4.62e-11]\n",
            "Eval: 100%|██████████| 163/163 [02:38<00:00,  1.03it/s, accuracy=0.988, avg_loss=0.0338, loss=4.65e-5, lr=]\n",
            "Epochs: 100%|██████████| 30/30 [18:37:31<00:00, 2235.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "memory released in device cuda\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 5.48 GiB. GPU 1 has a total capacity of 12.00 GiB of which 5.02 GiB is free. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 66.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m models_to_train \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvit_base_patch16_384\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m384\u001b[39m]\n\u001b[0;32m     28\u001b[0m                     ,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minception_v3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m384\u001b[39m]\n\u001b[0;32m     29\u001b[0m                     ,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxception\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m384\u001b[39m]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m                     ,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResNet101\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m384\u001b[39m]                    \n\u001b[0;32m     35\u001b[0m                   ]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m models_to_train:          \n\u001b[0;32m     38\u001b[0m     \u001b[43mtraining_class_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_path_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_path_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_path_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m---> 39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#training_class_models(program_path,image_path_train,image_path_val,image_path_test,\\\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m#    i[0],lr,epochs,i[1]).test_with_saved_model()\u001b[39;00m\n",
            "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtraining_class_models.initiate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedir_to_save_model();\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_and_val();\n\u001b[1;32m--> 411\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtraining_class_models.test_model\u001b[1;34m(self, saved_model)\u001b[0m\n\u001b[0;32m    398\u001b[0m         writercsv\u001b[38;5;241m.\u001b[39mwriterow(row)\n\u001b[0;32m    399\u001b[0m         f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 401\u001b[0m inputs, targets, preds \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_and_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m compute_metrics(inputs, targets, preds)\n",
            "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtraining_class_models.test_model.<locals>.load_model_and_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m    326\u001b[0m         preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)                    \n\u001b[0;32m    327\u001b[0m         all_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((all_preds,preds))\n\u001b[1;32m--> 328\u001b[0m         all_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m         all_targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((all_targets,targets))                            \n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m#if torch.device(self.device) != 'cpu':\u001b[39;00m\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.48 GiB. GPU 1 has a total capacity of 12.00 GiB of which 5.02 GiB is free. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 66.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "#on colab:\n",
        "#program_path = \"/content/drive/MyDrive/Mestrado/programa_mestrado\"\n",
        "#image_path_train = \"/content/drive/MyDrive/Mestrado/programa_mestrado/imagens/train\"\n",
        "#image_path_val = \"/content/drive/MyDrive/Mestrado/programa_mestrado/imagens/val\"\n",
        "\n",
        "program_path = \".\"\n",
        "image_path_train = \"./images/train\"\n",
        "image_path_val = \"./images/val\"\n",
        "image_path_test = \"./images/test\"\n",
        "\n",
        "# Learning rate for the model\n",
        "lr = 1e-5\n",
        "# Number of training epochs\n",
        "epochs = 30\n",
        "\n",
        "#if os.path.exists(\"./runs\"):\n",
        "#    del_file(\"./runs\")  # clear the runs folder, NOTICE this may be DANGEROUS\n",
        "#else:\n",
        "#    os.makedirs(\"./runs\")\n",
        "\n",
        "\n",
        "#if os.path.exists(\"./models\"):\n",
        "#    del_file(\"./models\")  # clear the models folder, NOTICE this may be DANGEROUS\n",
        "#else:\n",
        "#    os.makedirs(\"./models\")\n",
        "\n",
        "models_to_train = [['vit_base_patch16_384',384]\n",
        "                    ,['inception_v3',384]\n",
        "                    ,['xception',384]\n",
        "                    ,['vgg16',384]\n",
        "                    ,['vgg19',384]\n",
        "                    ,['visformer_small',224]\n",
        "                    ,['ResNet50',384]\n",
        "                    ,['ResNet101',384]                    \n",
        "                  ]\n",
        "\n",
        "for i in models_to_train:          \n",
        "    training_class_models(program_path,image_path_train,image_path_val,image_path_test,\\\n",
        "        i[0],lr,epochs,i[1]).initiate()\n",
        "    \n",
        "    #training_class_models(program_path,image_path_train,image_path_val,image_path_test,\\\n",
        "    #    i[0],lr,epochs,i[1]).test_with_saved_model()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "076f1780a9e44ac8b5f0918f1cb4b87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93e2b4c165da48669fa85bba7ee88dd8",
              "IPY_MODEL_1d41bcdc94624caab1ffc4d2e8c4cc7b",
              "IPY_MODEL_d92e58a73f864ee18eec882d927a8299"
            ],
            "layout": "IPY_MODEL_1319f2732d9741e3936e4f53ad0a643e"
          }
        },
        "10492de5016b460999e9fe3cee9fbb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1319f2732d9741e3936e4f53ad0a643e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d41bcdc94624caab1ffc4d2e8c4cc7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44efa5874cb24d7babed124489cdde0f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac7afb88998e4843a67fb20113e0a1c6",
            "value": 0
          }
        },
        "2132dd337d3348d184c99a7ecf2f166c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3526ad0cb5584bbfaf624969309389ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39398fdfaf734f52b801fba0feb1c6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e60f29667de4495a26844695fea3a81",
            "max": 347452074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dab21b2bb5084dddaab1daf010a31a54",
            "value": 347452074
          }
        },
        "3c3a12e9e4cb424a97d3c0c2a088a412": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44efa5874cb24d7babed124489cdde0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5120b6ab7d224565bace0d12ea3484b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64fd989943b643faa1ddd53c365142ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d74f4eee17424416a46f8f9c835a9681",
            "value": 0
          }
        },
        "558e0cd7f1fe42218d5474c0bfa05c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "629e0b80edc34f028d69938ca23c6ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ae4732fc2c40948a27ce0a1bd33850": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3526ad0cb5584bbfaf624969309389ec",
            "placeholder": "​",
            "style": "IPY_MODEL_d1633f97a3df4b58b2fc03b68239a06e",
            "value": " 0/1 [01:14&lt;?, ?it/s]"
          }
        },
        "64fd989943b643faa1ddd53c365142ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c770ee9b8cc4621be90762fdb5f0625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e60f29667de4495a26844695fea3a81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82b65f9dcd574cac86f2baa1152e2efa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "885d3ecb2a344b7dbe8345af191f78ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e2b4c165da48669fa85bba7ee88dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93f7c34e5c341f1bae3dc5bba397645",
            "placeholder": "​",
            "style": "IPY_MODEL_558e0cd7f1fe42218d5474c0bfa05c3c",
            "value": "Epochs:   0%"
          }
        },
        "96ad557a7d0c410a80c5f9f45bd8ed28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2132dd337d3348d184c99a7ecf2f166c",
            "placeholder": "​",
            "style": "IPY_MODEL_3c3a12e9e4cb424a97d3c0c2a088a412",
            "value": " 347M/347M [00:02&lt;00:00, 161MB/s]"
          }
        },
        "96e70b0456b549a2ad3f38f0ff9395fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee107c49bc1f4dfeb8467ecf9baf4420",
              "IPY_MODEL_39398fdfaf734f52b801fba0feb1c6ae",
              "IPY_MODEL_96ad557a7d0c410a80c5f9f45bd8ed28"
            ],
            "layout": "IPY_MODEL_f91f38d8898b4e67a3dacda1c99e391d"
          }
        },
        "ac7afb88998e4843a67fb20113e0a1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4df6842f8ce4bd1bc450bcc18401f41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82cedbc70d84c61b89b1f5a6b77bf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e17ea787578943a5ab471521b3d72bf9",
              "IPY_MODEL_5120b6ab7d224565bace0d12ea3484b6",
              "IPY_MODEL_63ae4732fc2c40948a27ce0a1bd33850"
            ],
            "layout": "IPY_MODEL_885d3ecb2a344b7dbe8345af191f78ed"
          }
        },
        "c93f7c34e5c341f1bae3dc5bba397645": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1633f97a3df4b58b2fc03b68239a06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d74f4eee17424416a46f8f9c835a9681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d92e58a73f864ee18eec882d927a8299": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629e0b80edc34f028d69938ca23c6ad4",
            "placeholder": "​",
            "style": "IPY_MODEL_6c770ee9b8cc4621be90762fdb5f0625",
            "value": " 0/3 [00:45&lt;?, ?it/s]"
          }
        },
        "dab21b2bb5084dddaab1daf010a31a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e17ea787578943a5ab471521b3d72bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4df6842f8ce4bd1bc450bcc18401f41",
            "placeholder": "​",
            "style": "IPY_MODEL_ed1e7ef2cac440f1a1d598ce87f64a18",
            "value": "Train:   0%"
          }
        },
        "ed1e7ef2cac440f1a1d598ce87f64a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee107c49bc1f4dfeb8467ecf9baf4420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b65f9dcd574cac86f2baa1152e2efa",
            "placeholder": "​",
            "style": "IPY_MODEL_10492de5016b460999e9fe3cee9fbb35",
            "value": "model.safetensors: 100%"
          }
        },
        "f91f38d8898b4e67a3dacda1c99e391d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
