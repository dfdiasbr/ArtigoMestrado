{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nw-Aenn0phW"
      },
      "source": [
        "CÃ³digo para o projeto/artigo mestrado - 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xDiUvJo1bLM"
      },
      "source": [
        "Instalando bibiotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWyFOn5D1Zib",
        "outputId": "d8ce5535-197f-4901-f6f7-b4d3ea73e7b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
            "Collecting libclang>=13.0.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.4)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (69.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.10.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.6)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
            "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
            "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
            "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
            "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/26.4 MB 3.3 MB/s eta 0:00:08\n",
            "   ---------------------------------------- 0.3/26.4 MB 3.2 MB/s eta 0:00:09\n",
            "    --------------------------------------- 0.6/26.4 MB 4.0 MB/s eta 0:00:07\n",
            "   - -------------------------------------- 0.8/26.4 MB 5.7 MB/s eta 0:00:05\n",
            "   - -------------------------------------- 1.1/26.4 MB 4.6 MB/s eta 0:00:06\n",
            "   -- ------------------------------------- 1.9/26.4 MB 6.9 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 2.3/26.4 MB 7.2 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 2.8/26.4 MB 7.6 MB/s eta 0:00:04\n",
            "   ----- ---------------------------------- 3.5/26.4 MB 8.6 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 3.8/26.4 MB 8.4 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 4.6/26.4 MB 9.2 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 5.1/26.4 MB 9.7 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 5.5/26.4 MB 9.2 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 6.0/26.4 MB 9.4 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 6.8/26.4 MB 9.8 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 7.2/26.4 MB 10.0 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 8.0/26.4 MB 10.3 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 8.8/26.4 MB 10.6 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 9.4/26.4 MB 10.8 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 10.2/26.4 MB 11.1 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 11.0/26.4 MB 12.4 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 11.8/26.4 MB 13.6 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 12.3/26.4 MB 13.4 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 13.2/26.4 MB 14.2 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 14.0/26.4 MB 14.6 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 14.8/26.4 MB 14.6 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 15.7/26.4 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 16.3/26.4 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 16.9/26.4 MB 15.6 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 17.8/26.4 MB 16.8 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 18.3/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 19.0/26.4 MB 16.0 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 19.8/26.4 MB 16.0 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 20.5/26.4 MB 16.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 21.3/26.4 MB 16.0 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 22.0/26.4 MB 16.0 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 22.9/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 23.6/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 24.5/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 25.2/26.4 MB 16.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  25.9/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  26.4/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  26.4/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  26.4/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  26.4/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  26.4/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  26.4/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  26.4/26.4 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 26.4/26.4 MB 10.4 MB/s eta 0:00:00\n",
            "Downloading ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
            "   ---------------------------------------- 0.0/938.6 kB ? eta -:--:--\n",
            "   --------------------------------------  931.8/938.6 kB 20.0 MB/s eta 0:00:01\n",
            "   --------------------------------------- 938.6/938.6 kB 20.2 MB/s eta 0:00:00\n",
            "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
            "   ---------------------------------------- 0.0/422.5 kB ? eta -:--:--\n",
            "   --------------------------------------  419.8/422.5 kB 13.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 422.5/422.5 kB 6.6 MB/s eta 0:00:00\n",
            "Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "   ---------------------------------------- 0.0/442.0 kB ? eta -:--:--\n",
            "   --------------------------------------- 442.0/442.0 kB 13.5 MB/s eta 0:00:00\n",
            "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   --------------------- ------------------ 0.8/1.5 MB 17.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  1.5/1.5 MB 15.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.5/1.5 MB 13.5 MB/s eta 0:00:00\n",
            "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
            "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
            "   ---------------------------------------- 0.0/84.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 84.9/84.9 kB 2.4 MB/s eta 0:00:00\n",
            "Installing collected packages: libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, pyasn1, protobuf, opt-einsum, ml-dtypes\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.3\n",
            "    Uninstalling protobuf-4.25.3:\n",
            "      Successfully uninstalled protobuf-4.25.3\n",
            "Successfully installed flatbuffers-24.3.25 libclang-18.1.1 ml-dtypes-0.2.0 opt-einsum-3.3.0 protobuf-4.23.4 pyasn1-0.5.1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 wrapt-1.14.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboardX) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboardX) (4.23.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (2.2.1+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (0.17.1+cu118)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (2.2.1+cu118)\n",
            "Requirement already satisfied: filelock in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (10.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (0.9.16)\n",
            "Requirement already satisfied: torch in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (2.2.1+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (0.17.1+cu118)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (0.21.4)\n",
            "Requirement already satisfied: safetensors in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (3.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (2024.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->timm) (3.1.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from torchvision->timm) (10.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from jinja2->torch->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface_hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface_hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (10.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cjm_pandas_utils\n",
            "  Downloading cjm_pandas_utils-0.0.3-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting cjm_pil_utils\n",
            "  Downloading cjm_pil_utils-0.0.9-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting cjm_pytorch_utils\n",
            "  Downloading cjm_pytorch_utils-0.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting cjm_torchvision_tfms\n",
            "  Downloading cjm_torchvision_tfms-0.0.11-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting torchtnt\n",
            "  Downloading torchtnt-0.2.4-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pandas (from cjm_pandas_utils)\n",
            "  Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from cjm_pil_utils) (1.26.4)\n",
            "Requirement already satisfied: pillow in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from cjm_pil_utils) (10.1.0)\n",
            "Requirement already satisfied: torch in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from cjm_pytorch_utils) (2.2.1+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from cjm_pytorch_utils) (0.17.1+cu118)\n",
            "Collecting cjm-psl-utils (from cjm_torchvision_tfms)\n",
            "  Downloading cjm_psl_utils-0.0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: fsspec in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchtnt) (2024.2.0)\n",
            "Requirement already satisfied: tensorboard in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from torchtnt) (2.15.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchtnt) (24.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchtnt) (5.9.8)\n",
            "Collecting pyre-extensions (from torchtnt)\n",
            "  Downloading pyre_extensions-0.0.30-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchtnt) (4.10.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from torchtnt) (69.0.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchtnt) (4.66.2)\n",
            "Collecting tabulate (from torchtnt)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->cjm_pytorch_utils) (3.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->cjm_pytorch_utils) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->cjm_pytorch_utils) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->cjm_pytorch_utils) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from pandas->cjm_pandas_utils) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas->cjm_pandas_utils)\n",
            "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->cjm_pandas_utils)\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting typing-inspect (from pyre-extensions->torchtnt)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->torchtnt) (2.0.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->torchtnt) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->torchtnt) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->torchtnt) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboard->torchtnt) (3.6)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboard->torchtnt) (4.23.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->torchtnt) (2.31.0)\n",
            "Requirement already satisfied: six>1.9 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboard->torchtnt) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboard->torchtnt) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->torchtnt) (3.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tqdm->torchtnt) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->torchtnt) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->torchtnt) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from sympy->torch->cjm_pytorch_utils) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions->torchtnt)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->torchtnt) (3.2.2)\n",
            "Downloading cjm_pandas_utils-0.0.3-py3-none-any.whl (4.5 kB)\n",
            "Downloading cjm_pil_utils-0.0.9-py3-none-any.whl (8.0 kB)\n",
            "Downloading cjm_pytorch_utils-0.0.6-py3-none-any.whl (7.3 kB)\n",
            "Downloading cjm_torchvision_tfms-0.0.11-py3-none-any.whl (14 kB)\n",
            "Downloading torchtnt-0.2.4-py3-none-any.whl (163 kB)\n",
            "   ---------------------------------------- 0.0/163.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 163.5/163.5 kB 4.8 MB/s eta 0:00:00\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "   ---------------------------------------- 0.0/179.2 kB ? eta -:--:--\n",
            "   --------------------------------------- 179.2/179.2 kB 10.6 MB/s eta 0:00:00\n",
            "Downloading cjm_psl_utils-0.0.4-py3-none-any.whl (5.9 kB)\n",
            "Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl (11.6 MB)\n",
            "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.6/11.6 MB 11.8 MB/s eta 0:00:01\n",
            "   ---- ----------------------------------- 1.3/11.6 MB 14.1 MB/s eta 0:00:01\n",
            "   ----- ---------------------------------- 1.6/11.6 MB 11.3 MB/s eta 0:00:01\n",
            "   ------- -------------------------------- 2.1/11.6 MB 11.4 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 2.4/11.6 MB 10.0 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 2.7/11.6 MB 10.3 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 3.1/11.6 MB 9.6 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 3.3/11.6 MB 9.6 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 3.8/11.6 MB 9.1 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 4.7/11.6 MB 10.0 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 5.5/11.6 MB 10.9 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 5.7/11.6 MB 10.4 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 6.2/11.6 MB 10.5 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 6.8/11.6 MB 10.9 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 7.7/11.6 MB 11.2 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 8.2/11.6 MB 11.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 9.1/11.6 MB 11.6 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 9.9/11.6 MB 11.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.3/11.6 MB 11.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 11.3/11.6 MB 12.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.6/11.6 MB 12.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.6/11.6 MB 12.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.6/11.6 MB 10.7 MB/s eta 0:00:00\n",
            "Downloading pyre_extensions-0.0.30-py3-none-any.whl (12 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: pytz, tzdata, torcheval, tabulate, mypy-extensions, cjm_pil_utils, typing-inspect, pandas, cjm-psl-utils, pyre-extensions, cjm_pandas_utils, cjm_pytorch_utils, torchtnt, cjm_torchvision_tfms\n",
            "Successfully installed cjm-psl-utils-0.0.4 cjm_pandas_utils-0.0.3 cjm_pil_utils-0.0.9 cjm_pytorch_utils-0.0.6 cjm_torchvision_tfms-0.0.11 mypy-extensions-1.0.0 pandas-2.2.2 pyre-extensions-0.0.30 pytz-2024.1 tabulate-0.9.0 torcheval-0.0.7 torchtnt-0.2.4 typing-inspect-0.9.0 tzdata-2024.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchmetrics) (2.2.1+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.2)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "   ---------------------------------------- 0.0/866.2 kB ? eta -:--:--\n",
            "   - ------------------------------------- 41.0/866.2 kB 653.6 kB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 235.5/866.2 kB 2.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 593.9/866.2 kB 4.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  860.2/866.2 kB 5.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 866.2/866.2 kB 4.6 MB/s eta 0:00:00\n",
            "Downloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.6 torchmetrics-1.4.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (3.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from seaborn) (3.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.13.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow\n",
        "%pip install tensorboardX\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install timm\n",
        "%pip install pillow\n",
        "%pip install cjm_pandas_utils cjm_pil_utils cjm_pytorch_utils cjm_torchvision_tfms torchtnt torcheval\n",
        "%pip install torchmetrics\n",
        "%pip install matplotlib\n",
        "%pip install seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MicqcgAEG34"
      },
      "source": [
        "Importando dependÃªncias necessÃ¡rias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xUOu7wjhEJRo"
      },
      "outputs": [],
      "source": [
        "# Import Python Standard Library dependencies\n",
        "#from copy import copy\n",
        "#import datetime\n",
        "#from glob import glob\n",
        "import json\n",
        "import math\n",
        "#import multiprocessing\n",
        "import os\n",
        "from pathlib import Path\n",
        "#import random\n",
        "#import urllib.request\n",
        "import timm\n",
        "import csv\n",
        "\n",
        "# Import utility functions\n",
        "#from cjm_pandas_utils.core import markdown_to_pandas\n",
        "from cjm_pil_utils.core import get_img_files\n",
        "#from cjm_psl_utils.core import download_file, file_extract\n",
        "from cjm_pytorch_utils.core import get_torch_device\n",
        "#from cjm_torchvision_tfms.core import ResizeMax, PadSquare\n",
        "\n",
        "# Import matplotlib for creating plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Import pandas module for data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Do not truncate the contents of cells and display all rows and columns\n",
        "pd.set_option('max_colwidth', None, 'display.max_rows', None, 'display.max_columns', None)\n",
        "\n",
        "# Import PIL for image manipulation\n",
        "from PIL import Image\n",
        "\n",
        "# Import timm library\n",
        "import timm\n",
        "\n",
        "# Import PyTorch dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.amp import autocast\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "torchvision.disable_beta_transforms_warning()\n",
        "import torchvision.transforms.v2  as transforms\n",
        "#from torchvision.transforms.v2 import functional as TF\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "from torcheval.metrics import MulticlassAccuracy\n",
        "from torchmetrics.classification import MulticlassConfusionMatrix\n",
        "from torchmetrics.classification import MulticlassF1Score\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9pDf6KewAr3",
        "outputId": "413df00c-59c5-4c6f-b808-52aecdc372d7"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining Class for the LeNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)  # Adapted for 3 input channels\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = None  # Initially defined as None\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        \n",
        "        # If fc1 has not been defined yet, define it now.\n",
        "        if self.fc1 is None:\n",
        "            self.fc1 = nn.Linear(x.size(1), 120).to(x.device)\n",
        "            \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class ImprovedLeNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ImprovedLeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "        self.fc1 = None  # Initially defined as None\n",
        "        self.fc2 = nn.Linear(256, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        \n",
        "        # If fc1 has not been defined yet, define it now.\n",
        "        if self.fc1 is None:\n",
        "            self.fc1 = nn.Linear(x.size(1), 256).to(x.device)\n",
        "        \n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6yDBCPF_Vs4"
      },
      "source": [
        "Defining the class for training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "rUxkKGOC0yB5",
        "outputId": "d0e080d9-f054-4d4f-bc0a-ca6b803c6aa4"
      },
      "outputs": [],
      "source": [
        "class training_class_models():\n",
        "    def __init__(self,program_path,image_path_train,image_path_val,image_path_test,\\\n",
        "        model_name,lr,epochs,img_size):\n",
        "        #torch.cuda.set_device(1)\n",
        "        self.device = get_torch_device()        \n",
        "        self.dtype = torch.float32        \n",
        "        self.model_name = model_name\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.img_size = img_size        \n",
        "        print(f\"device is:{self.device}\")                \n",
        "\n",
        "        self.program_path = Path(program_path)\n",
        "        self.image_path_train = Path(image_path_train)\n",
        "        self.image_path_val = Path(image_path_val)\n",
        "        self.image_path_test = Path(image_path_test)                \n",
        "                \n",
        "        #tensorboard configuration        \n",
        "        self.writer = SummaryWriter(f\"runs/{model_name}\")\n",
        "    \n",
        "    def prepare_images_and_classes(self):\n",
        "        \n",
        "        img_folder_paths_train = [folder_train for folder_train in self.image_path_train.iterdir() if folder_train.is_dir()]\n",
        "        img_folder_paths_val = [folder_val for folder_val in self.image_path_val.iterdir() if folder_val.is_dir()]\n",
        "\n",
        "        # Get a list of all image file paths from the image folders\n",
        "        class_file_paths_train = [get_img_files(folder) for folder in img_folder_paths_train]\n",
        "        class_file_paths_val = [get_img_files(folder) for folder in img_folder_paths_val]        \n",
        "\n",
        "        # Get all image files in the 'img_dir' directory\n",
        "        img_paths_train = [\n",
        "            file\n",
        "            for folder in class_file_paths_train # Iterate through each image folder\n",
        "            for file in folder # Get a list of image files in each image folder\n",
        "        ]\n",
        "        \n",
        "        # Get all image files in the 'img_dir' directory\n",
        "        img_paths_val = [\n",
        "            file\n",
        "            for folder in class_file_paths_val # Iterate through each image folder\n",
        "            for file in folder # Get a list of image files in each image folder\n",
        "        ]\n",
        "        \n",
        "        # Print the number of image files\n",
        "        print(f\"Number of train Images: {len(img_paths_train)}\")\n",
        "        \n",
        "        # Print the number of image files\n",
        "        print(f\"Number of val Images: {len(img_paths_val)}\")\n",
        "\n",
        "        ordered_classes_names = [\n",
        "            os.path.basename(folder)\n",
        "            for folder in self.image_path_train.iterdir() if folder.is_dir()\n",
        "        ]    \n",
        "\n",
        "        index = [\n",
        "            i for i in range(0,len(ordered_classes_names))\n",
        "        ]\n",
        "        \n",
        "        #create the mapping from the labels in train directory\n",
        "        self.labels_map = dict(zip(index,ordered_classes_names))                \n",
        "    \n",
        "    def data_preprocessing(self):\n",
        "        self.dataset_name = 'rockdataset'\n",
        "        \n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomRotation((0, 180)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),            \n",
        "            transforms.Resize([self.img_size, self.img_size]),\n",
        "            transforms.ColorJitter(brightness=0.15, contrast=0.3, saturation=0.3, hue=0.06),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        val_transforms = transforms.Compose([                \n",
        "            transforms.Resize([self.img_size, self.img_size]),    \n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "        train_data = datasets.ImageFolder(self.image_path_train,transform=train_transforms)\n",
        "        val_data = datasets.ImageFolder(self.image_path_val,transform=val_transforms)        \n",
        "                \n",
        "        self.train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "        self.val_dataloader = DataLoader(val_data, batch_size=32)        \n",
        "\n",
        "    def load_pretrained_model(self):\n",
        "        \n",
        "        if (self.model_name[0:6] == 'ResNet'):\n",
        "            if(self.model_name == \"ResNet50\"):\n",
        "                self.model = models.resnet50(pretrained=True)\n",
        "            elif(self.model_name == \"ResNet101\"):\n",
        "                self.model = models.resnet101(pretrained=True)\n",
        "            num_ftrs = self.model.fc.in_features\n",
        "            self.model.fc = nn.Linear(num_ftrs, len(self.labels_map))\n",
        "        elif(self.model_name == 'LeNet'):\n",
        "            self.model = ImprovedLeNet(num_classes=len(self.labels_map))            \n",
        "        elif(self.model_name == 'AlexNet'):\n",
        "            self.model = models.alexnet(pretrained=True)\n",
        "            num_ftrs = self.model.classifier[6].in_features\n",
        "            self.model.classifier[6] = nn.Linear(num_ftrs, len(self.labels_map))\n",
        "        else:\n",
        "            self.model = timm.create_model(self.model_name, pretrained=True, num_classes=len(self.labels_map))\n",
        "\n",
        "        # Set the device and data type for the model\n",
        "        self.model = self.model.to(device=self.device, dtype=self.dtype)\n",
        "\n",
        "        # Add attributes to store the device and model name for later reference\n",
        "        self.model.device = self.device\n",
        "        self.model.name = self.model_name\n",
        "        print(f\"model {self.model_name} loaded\")\n",
        "    \n",
        "    def makedir_to_save_model(self):        \n",
        "        # Create a directory to store the checkpoints if it does not already exist\n",
        "        checkpoint_dir = self.program_path/f\"models/{self.model_name}\"        \n",
        "\n",
        "        # Create the checkpoint directory if it does not already exist\n",
        "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # The model checkpoint path\n",
        "        self.checkpoint_path = checkpoint_dir/f\"{self.model_name}.pth\"\n",
        "\n",
        "        # Set file path\n",
        "        class_labels_path = checkpoint_dir/f\"{self.dataset_name}-classes.json\"\n",
        "\n",
        "        # Save class labels in JSON format\n",
        "        with open(class_labels_path, \"w\") as write_file:\n",
        "            json.dump(self.labels_map, write_file)        \n",
        "    \n",
        "    def train_and_val(self):\n",
        "        \n",
        "        # Function to run a single training/validation epoch\n",
        "        def run_epoch(model, dataloader, optimizer, metric, lr_scheduler, device, scaler, epoch_id, is_training):\n",
        "            # Set model to training mode if 'is_training' is True, else set to evaluation mode\n",
        "            model.train() if is_training else model.eval()\n",
        "\n",
        "            # Reset the performance metric\n",
        "            metric.reset()\n",
        "            # Initialize the average loss for the current epoch\n",
        "            epoch_loss = 0\n",
        "            # Initialize progress bar with total number of batches in the dataloader\n",
        "            progress_bar = tqdm(total=len(dataloader), desc=\"Train\" if is_training else \"Eval\")\n",
        "\n",
        "            # Iterate over data batches\n",
        "            for batch_id, (inputs, targets) in enumerate(dataloader):\n",
        "                # Move inputs and targets to the specified device (e.g., GPU)\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                # Enables gradient calculation if 'is_training' is True\n",
        "                with torch.set_grad_enabled(is_training):\n",
        "                    # Automatic Mixed Precision (AMP) context manager for improved performance\n",
        "                    with autocast(torch.device(device).type):\n",
        "                        outputs = model(inputs) # Forward pass\n",
        "                        loss = torch.nn.functional.cross_entropy(outputs, targets) # Compute loss\n",
        "\n",
        "                # Update the performance metric\n",
        "                metric.update(outputs.detach().cpu(), targets.detach().cpu())\n",
        "\n",
        "                # If in training mode\n",
        "                if is_training:\n",
        "                    if scaler:\n",
        "                        scaler.scale(loss).backward()\n",
        "                        scaler.step(optimizer)\n",
        "                        old_scaler = scaler.get_scale()\n",
        "                        scaler.update()\n",
        "                        new_scaler = scaler.get_scale()\n",
        "                        if new_scaler >= old_scaler:\n",
        "                            lr_scheduler.step()\n",
        "                    else:\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        lr_scheduler.step()\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                loss_item = loss.item()\n",
        "                epoch_loss += loss_item\n",
        "                \n",
        "                # Update progress bar\n",
        "                progress_bar.set_postfix(accuracy=metric.compute().item(),\n",
        "                                        loss=loss_item,\n",
        "                                        avg_loss=epoch_loss/(batch_id+1),\n",
        "                                        lr=lr_scheduler.get_last_lr()[0] if is_training else \"\")\n",
        "                progress_bar.update()\n",
        "\n",
        "                # If loss is NaN or infinity, stop training\n",
        "                if is_training:\n",
        "                    stop_training_message = f\"Loss is NaN or infinite at epoch {epoch_id}, batch {batch_id}. Stopping training.\"\n",
        "                    assert not math.isnan(loss_item) and math.isfinite(loss_item), stop_training_message\n",
        "            \n",
        "            #write in tensorboard\n",
        "            if self.writer is not None:                \n",
        "                if(is_training):\n",
        "                    self.writer.add_scalar(\"Train/loss\",float(epoch_loss),epoch_id + 1)\n",
        "                    self.writer.add_scalar(\"Train/ACC\",float(metric.compute().item()),epoch_id + 1)\n",
        "                else:\n",
        "                    self.writer.add_scalar(\"Val/loss\",float(epoch_loss),epoch_id + 1)\n",
        "                    self.writer.add_scalar(\"Val/ACC\",float(metric.compute().item()),epoch_id + 1)\n",
        "            \n",
        "            progress_bar.close()\n",
        "            if self.writer is not None:                \n",
        "                self.writer.close()\n",
        "            \n",
        "            return epoch_loss / (batch_id + 1)\n",
        "        \n",
        "        def optimizer_lr_scheduler_metrics():\n",
        "            # AdamW optimizer; includes weight decay for regularization\n",
        "            optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, eps=1e-3)\n",
        "\n",
        "            # Learning rate scheduler; adjusts the learning rate during training\n",
        "            lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
        "                                                            max_lr=self.lr,\n",
        "                                                            total_steps=self.epochs*len(self.train_dataloader))\n",
        "\n",
        "            # Performance metric: Multiclass Accuracy\n",
        "            metric = MulticlassAccuracy()\n",
        "            \n",
        "            return optimizer, lr_scheduler, metric\n",
        "        \n",
        "        def train_loop(model, train_dataloader, valid_dataloader, optimizer, metric, lr_scheduler, device, epochs, checkpoint_path, use_scaler=False):\n",
        "            # Initialize a gradient scaler for mixed-precision training if the device is a CUDA GPU\n",
        "            scaler = GradScaler() if device.type == 'cuda' and use_scaler else None\n",
        "            best_loss = float('inf')\n",
        "\n",
        "            # Iterate over each epoch\n",
        "            for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "                # Run training epoch and compute training loss\n",
        "                train_loss = run_epoch(model, train_dataloader, optimizer, metric, lr_scheduler, device, scaler, epoch, is_training=True)\n",
        "                # Run validation epoch and compute validation loss\n",
        "                with torch.no_grad():\n",
        "                    valid_loss = run_epoch(model, valid_dataloader, None, metric, None, device, scaler, epoch, is_training=False)\n",
        "\n",
        "                # If current validation loss is lower than the best one so far, save model and update best loss\n",
        "                if valid_loss < best_loss:\n",
        "                    best_loss = valid_loss\n",
        "                    metric_value = metric.compute().item()\n",
        "                    torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "                    training_metadata = {\n",
        "                        'epoch': epoch,\n",
        "                        'train_loss': train_loss,\n",
        "                        'valid_loss': valid_loss,\n",
        "                        'metric_value': metric_value,\n",
        "                        'learning_rate': lr_scheduler.get_last_lr()[0],\n",
        "                        'model_architecture': model.name\n",
        "                    }\n",
        "\n",
        "                    # Save best_loss and metric_value in a JSON file\n",
        "                    with open(Path(checkpoint_path.parent/'training_metadata.json'), 'w') as f:\n",
        "                        json.dump(training_metadata, f)\n",
        "                    \n",
        "                    \n",
        "\n",
        "            # If the device is a GPU, empty the cache            \n",
        "            if str(device) != 'cpu':\n",
        "                getattr(torch, device.type).empty_cache()\n",
        "                print(f\"memory released in device {device}\")\n",
        "        \n",
        "        optimizer, lr_scheduler, metric = optimizer_lr_scheduler_metrics()\n",
        "        \n",
        "        train_loop(model=self.model,\n",
        "           train_dataloader=self.train_dataloader,\n",
        "           valid_dataloader=self.val_dataloader,\n",
        "           optimizer=optimizer,\n",
        "           metric=metric,\n",
        "           lr_scheduler=lr_scheduler,\n",
        "           device=torch.device(self.device),\n",
        "           epochs=self.epochs,\n",
        "           checkpoint_path=self.checkpoint_path,\n",
        "           use_scaler=True)\n",
        "        \n",
        "    def test_model(self,saved_model=False):                \n",
        "        from torchmetrics.classification import MulticlassAccuracy\n",
        "        \n",
        "        checkpoint_dir = self.program_path/f\"models/{self.model_name}\"\n",
        "        checkpoint_path = checkpoint_dir/f\"{self.model_name}.pth\"\n",
        "            \n",
        "        def load_model_and_test():\n",
        "            #alternating GPU\n",
        "            #torch.cuda.set_device(1)\n",
        "            self.device = get_torch_device()\n",
        "            \n",
        "            test_transforms = transforms.Compose([                \n",
        "            transforms.Resize([self.img_size, self.img_size]),    \n",
        "            transforms.ToTensor()\n",
        "            ])\n",
        "            \n",
        "            test_data = datasets.ImageFolder(self.image_path_test,transform=test_transforms)\n",
        "            test_dataloader = DataLoader(test_data, batch_size=32)        \n",
        "                                            \n",
        "            if(saved_model):    \n",
        "                self.model.load_state_dict(torch.load(checkpoint_path))\n",
        "            \n",
        "            # Set the device and data type for the model\n",
        "            self.model = self.model.to(device=self.device, dtype=self.dtype)\n",
        "            \n",
        "            # Setting the model to evaluate\n",
        "            self.model.eval()\n",
        "                        \n",
        "            all_preds = torch.empty((0, len(self.labels_map)), dtype=torch.float32).to(self.device)\n",
        "            all_targets = torch.empty((0), dtype=torch.float32).to(self.device)\n",
        "                        \n",
        "            with torch.no_grad():\n",
        "                # Iterate over test data\n",
        "                for batch_id, (inputs, targets) in enumerate(test_dataloader):\n",
        "                    # Move inputs and targets to the specified device (e.g., GPU)\n",
        "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "                    preds = self.model(inputs)                    \n",
        "                    all_preds = torch.cat((all_preds,preds))                    \n",
        "                    all_targets = torch.cat((all_targets,targets))                            \n",
        "                        \n",
        "            if str(self.device) != 'cpu':\n",
        "                getattr(torch, self.device).empty_cache()\n",
        "                print(f\"memory released in device {self.device} - test phase\")\n",
        "            \n",
        "            \n",
        "            return all_targets, all_preds            \n",
        "        \n",
        "        def compute_metrics(targets, preds):\n",
        "                                    \n",
        "            targets = targets.detach().cpu()\n",
        "            preds = preds.detach().cpu()\n",
        "            metric = MulticlassConfusionMatrix(len(self.labels_map))\n",
        "            cm = metric(preds, targets)            \n",
        "            acc = MulticlassAccuracy(len(self.labels_map))\n",
        "            acc(preds, targets)\n",
        "            acc = acc.compute().item()            \n",
        "            f1score = MulticlassF1Score(len(self.labels_map))\n",
        "            f1score(preds, targets)\n",
        "            f1score = f1score.compute().item()\n",
        "            \n",
        "            figurecm = plt.figure(figsize=(6,6))\n",
        "            sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "            plt.ylabel('Actual label');\n",
        "            plt.xlabel('Predicted label');            \n",
        "            all_sample_title = 'Confusion Matrix - '+self.model_name+ '\\n acc: %.6f' % (acc)+' F1: %.6f' % (f1score)\n",
        "            plt.title(all_sample_title, size = 9);\n",
        "            figurecm.savefig(Path(checkpoint_path.parent/'confusionmatrix.jpg'))                                    \n",
        "            \n",
        "            save_data_test(acc,f1score)\n",
        "        \n",
        "        def save_data_test(test_acc, test_f1score):\n",
        "            row = [self.model_name, test_acc, test_f1score]\n",
        "    \n",
        "            with open('./metrics.csv', 'a',encoding='UTF8', newline='') as f:        \n",
        "                writercsv = csv.writer(f)\n",
        "                writercsv.writerow(row)\n",
        "                f.close()\n",
        "                                        \n",
        "        targets, preds = load_model_and_test()\n",
        "        compute_metrics(targets, preds)\n",
        "        \n",
        "\n",
        "    def initiate(self):\n",
        "       self.prepare_images_and_classes()\n",
        "       self.data_preprocessing()\n",
        "       self.load_pretrained_model()\n",
        "       self.makedir_to_save_model()\n",
        "       self.train_and_val()\n",
        "       self.test_model()\n",
        "    \n",
        "    def test_with_saved_model(self):\n",
        "        is_saved_model = True\n",
        "        self.prepare_images_and_classes()\n",
        "        self.data_preprocessing()\n",
        "        self.load_pretrained_model()        \n",
        "        self.test_model(is_saved_model)   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device is:cpu\n",
            "Number of train Images: 91\n",
            "Number of val Images: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model AlexNet loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|ââââââââââ| 3/3 [03:43<00:00, 74.62s/it, accuracy=0.253, avg_loss=1.76, loss=1.55, lr=4.63e-6]\n",
            "Eval: 100%|ââââââââââ| 1/1 [00:11<00:00, 11.09s/it, accuracy=0.353, avg_loss=1.17, loss=1.17, lr=]\n",
            "Train: 100%|ââââââââââ| 3/3 [03:45<00:00, 75.01s/it, accuracy=0.297, avg_loss=1.64, loss=1.84, lr=1.33e-6]\n",
            "Eval: 100%|ââââââââââ| 1/1 [00:11<00:00, 11.56s/it, accuracy=0.353, avg_loss=1.14, loss=1.14, lr=]\n",
            "Epochs: 100%|ââââââââââ| 2/2 [07:52<00:00, 236.25s/it]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAHwCAYAAABQR52cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDL0lEQVR4nO3dd3wVVf7/8fclQAikAyH03glBQFhEKbtIlapiAQmIWOiwKMSVpkLAVVGkSpdFCIIggthAQBSUFmlSDSBCaEpJIAlJ5vcHP+/XaxLIhUxumHk99zGPBzkz98znZtbHJ58zc+Y4DMMwBAAA7mp5PB0AAAC4cyR0AAAsgIQOAIAFkNABALAAEjoAABZAQgcAwAJI6AAAWAAJHQAACyChAwBgASR0AAAsgIQOAICH/fbbb+revbsKFy4sHx8fhYWFafv27W71kdek2AAAQBb88ccfaty4sZo3b661a9eqaNGiOnz4sIKCgtzqx8HiLAAAeM6IESP03Xff6dtvv72jfhhyBwDAg1atWqX69evr0UcfVUhIiO655x7NmjXL7X6o0AEAMEFSUpKSkpJc2ry9veXt7e3SVqBAAUnS0KFD9eijj2rbtm0aNGiQZsyYoYiIiCyfj4QOALCtxBTz+p7w+hiNHTvWpW306NEaM2aMS1v+/PlVv359ff/99862gQMHatu2bdqyZUuWz8dDcQAA2zKzpI2MjNTQoUNd2v5enUtS8eLFVaNGDZe26tWra/ny5W6dj4QOAIAJMhpez0jjxo118OBBl7ZDhw6pbNmybp2PhA4AsC1DZt51dmTpqCFDhui+++7T+PHj1bVrV/344496//339f7777t3Nu6hAwDs6up181JgwXxZS+iStHr1akVGRurw4cMqX768hg4dqj59+rh1PhI6AMC2riabmNDzZz2hZwfmoQMAYAHcQwcA2JaVhqip0AEAsAAqdACAbVnpKTISOgDAtnLDtLXswpA7LOnZZ59VcHCwQkND76ifNm3aaNq0adkUlWd9++23KlWqlMfOP3/+fNWpU8dj5wesjoQOj9i8ebPatGmjoKAgBQYGKjw8XG+88YaSk5Ozpe9ly5YpNjZWcXFxd9TX2rVr1bdv3zuOKSM9e/aUw+HQ7NmzXdo/+ugjORwOderUKUv9bNiwQYGBgbc87oEHHtDJkydvI1L3PP3003I4HPr5559NO0e5cuXk6+urM2fOONtiYmLkcGS9IipXrpxWrlxpQnS4qxgmbjmMhI4ct3r1arVp00atWrXS4cOHdfHiRUVHR2v//v06ffr0HfcfGxurMmXKKCAgIBuiNVfVqlU1b948l7Z58+apWrVq2Xqe69evZ2t/mbly5YqWLl2q4OBgzZkzx9RzFShQQK+++qqp5wDuJiR05CjDMDRw4EANHz5cgwcPVpEiRSRJ1apV0/z5853vLt6+fbsaN26swMBA1ahRQ4sXL3b2MWbMGLVv3179+/dXYGCgypQpo+joaEnS5MmT1adPH+3Zs0e+vr7q2bNnhhVsp06dnCse/f777+rcubNztKBevXo6fvy4JKlZs2Z65513nJ/78ssvdc899yggIEB169bV119/7dzXs2dP9enTR48//rj8/PxUtWpVbdiw4aa/jwcffFDHjx/XoUOHJEmnTp3Stm3b0lXnL730ksqWLSs/Pz/VqFFDH330kSTpwoULatOmjS5duiRfX1/5+vrq22+/dQ5vjx49WqGhoXr88cddfg+XL19WxYoVXUYH2rdvr169et003luJjo5WoUKFNHHiRC1cuPCmf0jEx8erf//+KlOmjEJCQtSjRw9dunRJkvTiiy+qadOmSktLkyQtW7ZMoaGhOnv2rMvvZN68eTp69GiG/RuGocmTJ6tatWoKDAxUs2bNnKMGjz76qE6cOKEnnnhCvr6+ev755+/oe+PuZaECnYSOnHX48GHFxsbqiSeeyPSYixcvqnXr1nr88cd17tw5TZ8+XX369NF3333nPOaLL75QkyZNdOHCBb3++ut65plndOXKFQ0cOFAzZsxQWFiY4uPjNX/+/FvG9OabbyolJUW//fabLly4oDlz5sjPzy/dcUeOHFHHjh01cuRIXbhwQS+//LI6dOig2NhY5zHR0dF6/vnndfHiRT311FPq2bPnTc/t5eWlHj16aO7cuZKkBQsWqGvXrukWdAgPD9e2bdt08eJFjRo1Sk899ZRiY2NVuHBhrV27VgEBAYqPj1d8fLweeOABSdLevXuVN29enThxQgsXLnTpz9/fXx9++KGGDRumAwcO6N1339WhQ4c0ZcqUW/6+bmbOnDnq1q2bHn/8cSUkJOjTTz/N9Ninn35av//+u3bv3q3Y2Fhdv35d/fv3lySNGzdOCQkJev3113X8+HE9++yz+uCDDxQSEuL8fJUqVfTUU0/plVdeybD/6dOna86cOfr00091/vx5denSRe3bt1dycrI++ugjlSlTRosXL1Z8fLxmzJhxR98byA1I6MhR586dkySVLFky02PWrFmjokWLasCAAcqXL5+aNm2qJ598UgsWLHAeU7duXXXt2lVeXl566qmnlJyc7Kxy3ZUvXz5duHBBhw8flpeXl+rUqaPg4OB0x0VHR6tZs2bq0qWL8ubNq0ceeUT333+/y+hB27Zt1axZM3l5ealXr146fvy4Lly4cNPz9+zZUwsXLlRKSormz5+fYZXcrVs3hYSEyMvLS48//riqVavmsnZyRgICAvSf//xH+fPnV8GCBdPtb9iwoYYPH+78I2Xx4sUqVKjQTfu8mf3792vr1q2KiIiQr6+vOnfunOmw+7lz57R8+XJNnTpVgYGBKlSokF599VVFR0crNTVV+fPn1+LFizVp0iS1bdtWvXv3VsuWLdP1M2bMGH366afatWtXun1Tp07Vq6++qsqVKytv3rwaOHCgrl27ph9++OG2vyOsxzDM23IaCR056s8h9t9++y3TY06ePKly5cq5tFWoUMHlga6/Pr3ucDjk4+OjK1eu3FZML774oh544AF17dpVoaGhGjRokK5du3bHcf2ZHG8VV5UqVVS+fHmNGjVK+fPnV/369dMdM2nSJNWsWVMBAQEKDAzU3r17df78+Zv2W7JkSeXJc/P/xHv37q1jx46padOmqlu3bqbH1axZ0zmkv2jRogyPmTNnjsLDwxUeHi5JioiI0BdffJHhtT527JjS0tJUvnx5BQYGKjAwUPfee6/y5MnjfJCxcuXKatasmQ4dOqRhw4ZleM7ixYtr4MCBGjFiRIbn6N69u7P/wMBA/fHHHznyYCDgCSR05KgqVaqoXLlyWrJkSabHlCpVSseOHXNpO3bs2G1PufL19dW1a9f013WI/vrwna+vryZOnKiDBw9qy5YtWrduXYZT1bI7rr/q1auXJkyYkGF1vnnzZo0ZM0YffPCB/vjjD128eFG1atVyfp/Mkvatkrl0I6G3b99eP/zwg1atWpXpcfv27XMO6Xfr1i3d/uvXr2vhwoU6dOiQQkNDFRoaqm7duik1NTXD2x6lS5dWnjx5dOrUKV28eNG5JSYmOkdvli1bpq1bt6pdu3bq169fprENHz5c27dv1/r169Od46OPPnLp/+rVq87bPVn5/cD6DBP/l9P4fzRylMPh0HvvvacJEybovffecw5HHzp0SL1799bx48fVtm1bnT17VtOmTVNKSoq+/fZbLVq0SD169Litc1apUkX58uXThx9+qNTUVC1evNhliHb16tU6dOiQ0tLS5O/vr3z58ilv3vTvXHrssce0YcMGffLJJ0pJSdHHH3+sTZs26fHHH7+9X8ZfPPnkk/ryyy8zXC7x8uXL8vLyUtGiRZWWlqa5c+dq7969zv3FihXTlStXXB4Yy4rJkyfr0KFDWrBggebOnavevXvr1KlTtxX/qlWrdPnyZe3cuVMxMTGKiYnRTz/9pJEjR2ru3Ln6+6KOoaGh6tSpk/r37+8caYiLi9OKFSskSSdOnNBzzz2nBQsW6IMPPtCuXbsyXRs6ICBAL7/8ssaPH+/S3q9fP40aNUoHDx6UdOP3+MknnzhHTIoVK5bpA3WwD4bcgTvw0EMPae3atVqzZo0qVqyowMBAPfLII6pWrZqKFy+uoKAgrV27Vv/73/9UuHBhPfvss5o+fbruv//+2zqfv7+/Zs2apREjRqhw4cL67rvv1KpVK+f+I0eOqHXr1s4nyBs1aqQXXnghXT+VKlXSxx9/rNGjRys4OFivvvqqVqxYoQoVKtz27+JPPj4+atGiRYYP47Vu3VqPPPKIwsLCVKJECe3bt0+NGzd27q9atap69+6tGjVqKDAwUJs3b77l+Xbv3q1XXnnFed/8oYce0pNPPqmnnnrK+WS5O+bMmaMnnnhC1apVc1booaGhGjhwoE6dOqVvvvkm3Wfmz5/vHGr39/fXAw88oB07dig1NVXdunVTr1691LJlS/n7+2vx4sV66aWXMp3b3r9//3T3//v376+ePXuqS5cu8vf3V/Xq1fXhhx8697/88suaMmWKAgMDTXvXAJCTWA8dAGBbf1xNNa3voIJepvWdESp0AAAsgMVZAAC2ZaUxaip0AAAsgAodAGBbnpheZhYqdAAALICEDkv78/3gQUFBCg4O1oABA5SSkpLp8QMGDFDp0qXl7++vkiVLavDgwS5Luj7yyCMqXry4/P39Vb58eb3++uvOfUlJSWrWrJlCQkLk7++vatWqucydPnnypO677z4VLlxYAQEBqlOnjnPetSTt3LlT9erVU3BwsAIDA3Xfffdp06ZNzv1r165VWFiY87s8+OCD2rNnT6bfZcyYMcqbN6/zDW++vr7Ol6rs3btXrVq1UpEiReRwOHTx4kW3fq+S9N133yk8PFwFCxZUnTp1tGXLlkyPPX36tDp06KASJUrI4XAoJibGZf/zzz/vEmfBggXlcDi0c+fOLH33+Ph4Pf/88ypevLgCAwPVq1cvXb161bl/6dKluu+++5yx/t2trjusy0rz0GUAFjZq1CgjPDzcOHXqlHHq1CkjPDzcGDt2bKbH79+/34iPjzcMwzDOnTtnNGvWzHjttdec+3fv3m0kJiYahmEYx48fN6pXr24sXLjQMAzDSElJMXbv3m1cv37dMAzD2LdvnxESEmJs2rTJMAzDiI+PNw4ePGikpqYahmEY3333nVGwYEHjl19+MQzDMM6fP28cO3bMSEtLM9LS0ozly5cbvr6+xtWrVw3DMJzfwTAM4/r168akSZOMihUrZvpdRo8ebXTs2DHDfQcOHDBmz55tfPrpp4Yk448//rjp7/HvLly4YAQGBhrvv/++kZiYaLz//vtGcHBwpv3ExcUZU6dONX744QdDkrFr166b9v/mm28aVapUcf58q+/+7LPPGg8++KDx+++/G3/88YfRsmVLo0+fPs79X331lREdHW28/vrrRnh4eLrz3eq6w7rOXrlu2pbTqNCRI95++21VrlxZfn5+qlixYrpVvQ4fPqwOHTqoaNGiCg4OVpcuXbK071bmzp2rV155RcWLF1fx4sX1n//856brdFevXt35ghLDMJQnTx4dPnzYuT8sLMy5EprD4XDZ7+XlpbCwMOdb5hwOhxwOh44cOSLpxrvdq1Spojx58jj7Tk1Ndb5OtnDhwipbtqwcDocMw5CXl5fi4+Od7zb/8zv8GZuXl5eOHTt2W2ud//kymlq1arn9WUlasWKFSpYsqT59+sjb21t9+vRRaGioy4jDXxUrVkx9+/ZVgwYNstT/nDlz9PTTTzt/vtV3X7FihUaMGOFcAvfll1/WwoULne/kb9Gihbp27ZrpokC3uu7A3YCEjhxRtmxZrV+/XpcvX9bs2bP14osvOpdDTUhIUIsWLVSrVi0dO3ZMcXFxGjBgwC33STfeOjdhwoQMz/nnQhx/HWKtU6eOTpw44Vx3OyMTJkyQr6+vQkJC9NNPP7mcT5L69u2rggULqkyZMoqPj0+3ROpDDz2kAgUKqEaNGipWrJg6d+7ssr927dry9vZWo0aN1LhxY+dyp38KDAxU/vz51alTJ/Xo0UPly5d37jtx4oQCAwNVoEABDRo0SJGRkcqXL1+m3+V2bd68Od0a8n+1e/fudEPXderU0e7du+/43Fu2bNHhw4fT/V5v9t3T0tJcXi+blpamxMREt5Lyra47LMpCC6LzlDtyxMMPP+z8d/PmzdWqVStt2LBBjRs31urVq5UvXz6NGzdODofDeYykm+77c39m4uPjJcklMf357ytXriggICDDz40YMUIjRozQzz//rEWLFrmsoCZJ06ZN05QpU7Rz506tWrVKQUFBLvtXr16t1NRUbd68WRs3bpSPj4/L/t27dys5OVlffvmlDhw4IC8v17dJXbx4UdeuXdPy5cuVmJjosq9MmTK6ePGirly5ogULFqh06dKZfn/pxlK0f/3+0dHRLq+9zcz9999/0/vq8fHx6RJ+YGDgba9491ezZ8/WQw89pGLFirm03+y7t2vXTlFRUc6V3v58r/vly5ezfN5bXXcgt6NCR45YtGiR6tat63zg67PPPnMuynH8+HFVrFjRmbD/6mb7bsXX11eSXKrxP/+d0TvT/6569eoKDw9PVylKN1bqql+/vvz8/DJc2tPLy0tNmzbVmTNn9N///jfd/vz58+uhhx7SN998k+FypD4+PurevbsmTZqU4bvZ/fz81LdvX/Xq1UuxsbGZfod27dq5rDaWlWSeFb6+vulGOS5dupSl3+vNxMfHa+nSperdu3emx2T03d955x2VKVNG4eHhqlevnjp06CDpxm0Md93susN6WG0NcMOJEycUERGhN954Q2fPntXFixfVtm1b5xBp2bJldfTo0XQrct1q360EBQWpVKlSLk9Ux8TEqHTp0plW5393/fr1mw7benK/YRhKTExMt6RrTqhdu3a6J9VjYmIUFhZ2R/0uWbJE/v7+atOmzU2P+/t3DwoK0ty5c/Xbb7/p+PHjqlSpkkJDQ1W1atXbiuNW1wXIjUjoMF18fLwMw1BISIjy5Mmjzz77TF9++aVzf7t27ZSUlKRRo0YpISFBycnJztW5brYvK3r16qVx48YpLi5OcXFxGj9+vJ555plM45w3b54uXrwowzC0Z88evf76686q9vjx41q+fLni4+OVlpam77//XpMnT3buj4mJ0VdffaVr164pJSVFa9as0aJFi5z7N27cqC1btig5OVnJycmaP3++vvnmGz344IOSbgzV7969WykpKbp69arGjx+vkydPqkmTJpJuJLsjR44oLS1NFy9e1KBBg1SoUCHVrVvXzSvyfwkxKSlJ0o0pd4mJiVn+w6lz5846efKk5syZo+TkZM2ZM0enT59O97zAXyUmJjpvISQnJysxMTHdym5z5sxRz549092GuNV3j42N1ZkzZ2QYhnbt2qUhQ4Zo7NixzjXPU1NTlZiYqOvXr6f77re67rA2pq0Bbho5cqRRuHBhIzAw0OjRo4fx2GOPGYMGDXLuP3DggNGmTRsjODjYCA4ONh5++OEs7WvdurUxbty4TM+bnJxs9O3b1wgMDDQCAwON/v37O6eVGYZhPPfcc8Zzzz1nGMaNaWUtWrQwgoODjUKFChnly5c3hg0bZiQkJBiGYRjHjh0z7r//fiMgIMDw8/Mzqlatarz++uvOaWjbtm0z6tevb/j5+Rn+/v5G7dq1jRkzZjjPtWbNGiMsLMzw9fU1AgMDjQYNGhjLli1z7p83b55RpUoVo1ChQkbhwoWNZs2aGevXr3fuj4qKMsqVK2cULFjQKFq0qNGuXbubTv+62bS12NjYDB/jiY2NNQzDMDZt2mQUKlQo074NwzC+/fZbIywszChQoIBRu3Zt47vvvnPuO378uFGoUCHj+PHjzraMzvfNN9849+/bt89wOBzG0aNH053rVt99xYoVRsmSJQ0fHx+jcuXKxqxZs1w+P2/evHTnLlu2rGEYt77usLa4S8mmbTmN5VMBALYVd9n9aZ9ZFeqf/TNQboan3AEA9mWhkpZ76AAAWAAVOgDAtlhtDQAA5CpU6AAA27LSY+FU6AAAWAAVOgDAtixUoFOhAwBgBZat0BNTPB0BckqBvJLPPf09HQZyyLVdU7jeNnJt1xRT+7fSPXTLJnQAAG7NOhmdIXcAACyACh0AYFtWGnKnQgcAwAKo0AEAtmWhAp0KHQAAK6BCBwDYFvfQAQBArkKFDgCwLSstn0pCBwDYl3XyOUPuAABYARU6AMC2LFSgU6EDAGAFVOgAANti2hoAAMhVqNABALZlpWlrVOgAAFgAFToAwL6sU6CT0AEA9mWhfM6QOwAAVkCFDgCwLaatAQCAXIUKHQBgW0xbAwAAuQoVOgDAvqxToFOhAwBgBSR0AIBtGSZuWTVmzBg5HA6XrVq1am5/F4bcAQC2lVumrdWsWVNff/218+e8ed1PzyR0AAA8LG/evAoNDb2jPhhyBwDYlmHi/9xx+PBhlShRQhUqVFC3bt104sQJt78LFToAACZISkpSUlKSS5u3t7e8vb1d2ho2bKj58+eratWqOn36tMaOHasHHnhAe/fulZ+fX5bPR4UOALAvE5+Ki4qKUkBAgMsWFRWVLoQ2bdro0UcfVe3atdWqVSt99tlnunjxopYuXerWV6FCBwDABJGRkRo6dKhL29+r84wEBgaqSpUqOnLkiFvno0IHANiWmdPWvL295e/v77JlJaHHx8fr6NGjKl68uFvfhYQOAIAHDRs2TBs3btSxY8f0/fffq3PnzvLy8tITTzzhVj8MuQMAbCs3zEM/efKknnjiCV24cEFFixbV/fffr61bt6po0aJu9UNCBwDAg5YsWZIt/ZDQAQC2ZaXlU0noAAD7sk4+56E4AACsgAodAGBbFirQqdABALACKnQAgG3lhmlr2YUKHQAAC6BCBwDYlpWmrVGhAwBgAVToAAD7sk6BTkIHANiXhfI5Q+4AAFgBFToAwLaYtgYAAHIVKnQAgG0xbQ0AAOQqVOgAAPuyToFOhW4FZ86cUeTwYWpyX0M1qFtbD3dqr31793g6LJjoua5NdGDNWP2xdZI2fTBM9WuW9XRIMBHXG1lBQr/LXb50ST27P6G8efNp6oxZ+njVGv37xeHy9w/wdGgwySMt62rivztr3My1avTkRO0+9JtWTeunokG+ng4NJuB6m8swcctpJPS73Nw5s1QsNFSvjYtSWO3aKlWqtO5rfL9Klynj6dBgkoHd/6l5H3+vhau26sAvcRowbomuJSYrolMjT4cGE3C9zWUY5m05jYR+l9v4zXrVrFlLw4YMVLMHGqnrw520/KOlng4LJsmX10v3VC+t9T8cdLYZhqH1PxxUg9rlPRgZzMD1hjs8+lDc+fPnNXfuXG3ZskVxcXGSpNDQUN13333q2bOnihYt6snw7gonT/6qpdGL9VREL/V+9nnt27NHE6NeV758+dShU2dPh4dsViTIV3nzeuns71dc2s9euKyq5Yp5KCqYhettPitNW/NYQt+2bZtatWqlggULqkWLFqpSpYqkGw94TZ48WRMmTNAXX3yh+vXr37SfpKQkJSUlubR5e3tLXt6mxZ6bpKUZqlmrlgYOHipJql69ho4cOayPli4hoQOAjXgsoQ8YMECPPvqoZsyYIYfD4bLPMAw9//zzGjBggLZs2XLTfqKiojR27FiXttGjR2vEK2OyO+RcqWjRoqpQsaJLW4UKFfT1V194KCKY6fwf8UpJSVVIsJ9Le0hhf8VduOyhqGAWrncOsE6B7rl76D/99JOGDBmSLplLksPh0JAhQxQTE3PLfiIjI3Xp0iWXLTIy0oSIc6c699TVsdhYl7bjx46pRImSHooIZrqekqpdP/+q5g2rOtscDoeaN6iiH3fH3uSTuBtxveEOjyX00NBQ/fjjj5nu//HHH1Ws2K3vEXl7e8vf399l8/a2x3C7JHXvEaE9u3/S7Pdn6MTx4/ps9adatmypHnviSU+HBpNM/t969ep8n7q1b6iq5Ytp8suPqaCPtz74ZKunQ4MJuN7mstK0NY8NuQ8bNkzPPvusduzYoX/961/O5H3mzBmtW7dOs2bN0ptvvump8O4atcJq6+13p2jyO29r5vSpKlmqlF4a/rLaPdTB06HBJMu+3KkiQb4a9UI7FSvsp90Hf1PHflPTPTgFa+B6I6schuG5xeOio6M1adIk7dixQ6mpqZIkLy8v1atXT0OHDlXXrl1vu+/ElOyKErldgbySzz39PR0Gcsi1XVO43jZybdcUU/v/4egl0/puWDFnX/Dl0Wlrjz32mB577DFdv35d58+flyQVKVJE+fLl82RYAACbYNpaNsuXL5+KFy/u6TAAALhr5YqEDgCAR1inQOfVrwAAWAEVOgDAtixUoFOhAwBgBVToAADbSvPczO1sR4UOAIAFUKEDAGzLOvU5CR0AYGMWGnFnyB0AACugQgcA2JaVXv1KhQ4AgAVQoQMAbCvNOgU6FToAAFZAhQ4AsC3uoQMAgFyFCh0AYFtWmodOQgcA2BZD7gAAIFehQgcA2BbT1gAAQK5ChQ4AsC3uoQMAgFyFCh0AYFtWmrZGhQ4AgAVQoQMAbMtKFToJHQBgW2k8FAcAAHITKnQAgG1ZacidCh0AAAugQgcA2BYvlgEAALkKFToAwLa4hw4AAHIVKnQAgG1ZaR46CR0AYFsMuQMAgFyFhA4AsC3DxO12TZgwQQ6HQ4MHD3brcyR0AAByiW3btmnmzJmqXbu2258loQMAbMswDNM2d8XHx6tbt26aNWuWgoKC3P48CR0AgFygX79+ateunVq0aHFbn+cpdwCAbaWZ2HdSUpKSkpJc2ry9veXt7Z3u2CVLlmjnzp3atm3bbZ+PCh0AABNERUUpICDAZYuKikp33K+//qpBgwZp0aJFKlCgwG2fz2HczkD/XSAxxdMRIKcUyCv53NPf02Egh1zbNYXrbSPXdk0xtf+PYk6Z1neH6oWzVKGvXLlSnTt3lpeXl7MtNTVVDodDefLkUVJSksu+zDDkDgCACTIbXv+7f/3rX9qzZ49LW69evVStWjUNHz48S8lcIqEDAGwsNwxR+/n5qVatWi5thQoVUuHChdO13wwJHQBgW1a660xCBwAgl9mwYYPbnyGhAwBsy8xpazmNaWsAAFgAFToAwLasdA+dCh0AAAugQgcA2JaFCnQqdAAArIAKHQBgWxYq0EnoAAD7SrPQmLtlE3oBy34zZMTsBRyQu3C9gfQsm/ZYbc0+WG3NXlhtzV7M/uPNOvU5D8UBAGAJlq3QAQC4FV4sAwAAchUqdACAbbE4CwAAyFWo0AEAtmWhW+gkdACAfVnpxTIMuQMAYAFU6AAA27JQgU6FDgCAFVChAwBsi3voAAAgV6FCBwDYVpp1CnQqdAAArIAKHQBgWxa6hU5CBwDYV5qFVkRnyB0AAAugQgcA2JaVhtyp0AEAsAAqdACAbTFtDQAA5CpZqtAnT56c5Q4HDhx428EAAJCTrPTq1ywl9EmTJmWpM4fDQUIHAMADspTQY2NjzY4DAIAcZ6EC/fbvoScnJ+vgwYNKSUnJzngAAMgxaYZ5W05zO6FfvXpVvXv3VsGCBVWzZk2dOHFCkjRgwABNmDAh2wMEAAC35nZCj4yM1E8//aQNGzaoQIECzvYWLVooOjo6W4MDAMBMhmGYtuU0t+ehr1y5UtHR0frHP/4hh8PhbK9Zs6aOHj2arcEBAICscTuhnzt3TiEhIenaExISXBI8AAC5na1fLFO/fn2tWbPG+fOfSXz27Nlq1KhR9kUGAACyzO0Kffz48WrTpo3279+vlJQUvfvuu9q/f7++//57bdy40YwYAQAwha0r9Pvvv18xMTFKSUlRWFiYvvzyS4WEhGjLli2qV6+eGTECAIBbuK3FWSpWrKhZs2ZldywAAOQoQ9Yp0W8roaempmrFihX6+eefJUk1atRQx44dlTcvi7cBAO4eVhpydzsD79u3Tx06dFBcXJyqVq0qSZo4caKKFi2qTz/9VLVq1cr2IAEAwM25fQ/9mWeeUc2aNXXy5Ent3LlTO3fu1K+//qratWvr2WefNSNGAABMYRjmbTnN7Qo9JiZG27dvV1BQkLMtKChI48aN07333putwQEAgKxxu0KvUqWKzpw5k6797NmzqlSpUrYEBQBATkgzDNO2nJalhH758mXnFhUVpYEDB2rZsmU6efKkTp48qWXLlmnw4MGaOHGi2fECAIAMZGnIPTAw0OW1roZhqGvXrs62P19C3759e6WmppoQJgAA2c92T7l/8803ZscBAADuQJYSetOmTc2OAwCAHOeJp9HNcttvgrl69apOnDih5ORkl/batWvfcVAAAOQETzy8ZpbbWj61V69eWrt2bYb7uYcOAEDOc3va2uDBg3Xx4kX98MMP8vHx0eeff64FCxaocuXKWrVqlRkxAgBgClu/WGb9+vX65JNPVL9+feXJk0dly5bVgw8+KH9/f0VFRaldu3ZmxAkAAG7C7Qo9ISFBISEhkm68Ie7cuXOSpLCwMO3cuTN7owMAwERpJm45ze2EXrVqVR08eFCSFB4erpkzZ+q3337TjBkzVLx48WwPEAAA3JrbQ+6DBg3S6dOnJUmjR49W69attWjRIuXPn1/z58/P7vgAADCNrZ9y7969u/Pf9erV0/Hjx3XgwAGVKVNGRYoUydbgAABA1tz2PPQ/FSxYUHXr1s2OWAAAyFEWKtCzltCHDh2a5Q7ffvvt2w4GAICcZLt3ue/atStLnf11ARcAAJBzWJwFAGBbhoXG3N2etobc58yZM4ocPkxN7muoBnVr6+FO7bVv7x5PhwUTPde1iQ6sGas/tk7Spg+GqX7Nsp4OCSbieiMrSOh3ucuXLqln9yeUN28+TZ0xSx+vWqN/vzhc/v4Bng4NJnmkZV1N/HdnjZu5Vo2enKjdh37Tqmn9VDTI19OhwQRcb3OlGeZtOY2EfpebO2eWioWG6rVxUQqrXVulSpXWfY3vV+kyZTwdGkwysPs/Ne/j77Vw1VYd+CVOA8Yt0bXEZEV0auTp0GACrrf1TZ8+XbVr15a/v7/8/f3VqFGjTBdAuxkS+l1u4zfrVbNmLQ0bMlDNHmikrg930vKPlno6LJgkX14v3VO9tNb/cNDZZhiG1v9wUA1ql/dgZDAD19t8uaFCL1WqlCZMmKAdO3Zo+/bt+uc//6mOHTtq3759bn0XEvpd7uTJX7U0erHKlC2n6e/PUdfHntDEqNe1auUKT4cGExQJ8lXevF46+/sVl/azFy4rtLC/h6KCWbje9tC+fXu1bdtWlStXVpUqVTRu3Dj5+vpq69atbvWTpafc3VkWtUOHDm4FcDO//vqrRo8erblz52Z6TFJSkpKSklzavL29JS/vbIsjN0tLM1SzVi0NHHzjXQHVq9fQkSOH9dHSJerQqbOHowOA3C23PeWempqqjz76SAkJCWrUyL3bKllK6J06dcpSZw6HQ6mpqW4FcDO///67FixYcNOEHhUVpbFjx7q0jR49WiNeGZNtceRmRYsWVYWKFV3aKlSooK+/+sJDEcFM5/+IV0pKqkKC/VzaQwr7K+7CZQ9FBbNwve9umRWc3t7pC849e/aoUaNGSkxMlK+vr1asWKEaNWq4db4sJfS0NHMWgrtV5f/LL7/cso/IyMh0b7Lz9vZW7vqbyzx17qmrY7GxLm3Hjx1TiRIlPRQRzHQ9JVW7fv5VzRtW1acbdku68Yd08wZVNCN6k4ejQ3bjepvPzGVOMys4x4wZk+7YqlWrKiYmRpcuXdKyZcsUERGhjRs3upXU7/hd7neiU6dOcjgcNx3yuNXb5zL7aycx5Y7Duyt07xGhiO5PaPb7M9SyVRvt3bNby5Yt1agxr3o6NJhk8v/Wa9arT2nH/hPavveY+j/ZXAV9vPXBJ+7db8PdgettLjOH3DMrODOSP39+VapUSdKNhc+2bdumd999VzNnzszy+W4roSckJGjjxo06ceKEkpOTXfYNHDgwy/0UL15c06ZNU8eOHTPcHxMTo3r16t1OiLZRK6y23n53iia/87ZmTp+qkqVK6aXhL6vdQ9n3LANyl2Vf7lSRIF+NeqGdihX20+6Dv6ljv6npHpyCNXC9716ZFZxZkZaWlm64/lbcTui7du1S27ZtdfXqVSUkJCg4OFjnz59XwYIFFRIS4lZCr1evnnbs2JFpQr9V9Y4bmjZrrqbNmns6DOSgGdGbGHK1Ea63eXJDiomMjFSbNm1UpkwZXblyRR9++KE2bNigL75w71kotxP6kCFD1L59e82YMUMBAQHaunWr8uXLp+7du2vQoEFu9fXiiy8qISEh0/2VKlXiPfIAAEs7e/asevToodOnTysgIEC1a9fWF198oQcffNCtftxO6DExMZo5c6by5MkjLy8vJSUlqUKFCnrjjTcUERGhLl26ZLmvBx544Kb7CxUqpKZNm7obIgAAWZKWC0r0OXPmZEs/br9YJl++fMqT58bHQkJCdOLECUlSQECAfv3112wJCgAAuMftCv2ee+7Rtm3bVLlyZTVt2lSjRo3S+fPntXDhQtWqVcuMGAEAMEUuKNCzjdsV+vjx41W8eHFJ0rhx4xQUFKQXXnhB586d0/vvv5/tAQIAgFtzu0KvX7++898hISH6/PPPszUgAAByipVmUnn0xTIAAHiShfK5+wm9fPnyN317W1Ze1woAALKX2wl98ODBLj9fv35du3bt0ueff64XX3wxu+ICAMB0uWHaWnZxO6Fn9vKYqVOnavv27XccEAAAcJ/bT7lnpk2bNlq+fHl2dQcAgOkME7eclm0JfdmyZQoODs6u7gAAgBtu68Uyf30ozjAMxcXF6dy5c5o2bVq2BgcAgJlsPW2tY8eOLgk9T548Klq0qJo1a6Zq1apla3AAACBr3E7oY8aMMSEMAAByXpp1CnT376F7eXnp7Nmz6dovXLggLy+vbAkKAICcYBiGaVtOczuhZxZkUlKS8ufPf8cBAQAA92V5yH3y5MmSJIfDodmzZ8vX19e5LzU1VZs2beIeOgDgrmKhZ+KyntAnTZok6UaFPmPGDJfh9fz586tcuXKaMWNG9kcIAABuKcsJPTY2VpLUvHlzffzxxwoKCjItKAAAcoKtp6198803ZsQBAADugNsPxT388MOaOHFiuvY33nhDjz76aLYEBQBATkgzzNtymtsJfdOmTWrbtm269jZt2mjTpk3ZEhQAAHCP20Pu8fHxGU5Py5cvny5fvpwtQQEAkBOsdA/d7Qo9LCxM0dHR6dqXLFmiGjVqZEtQAADkBCuttuZ2hT5y5Eh16dJFR48e1T//+U9J0rp167R48WJ99NFH2R4gAAC4NbcTevv27bVy5UqNHz9ey5Ytk4+Pj2rXrq2vv/5aTZs2NSNGAABMkWahIXe3E7oktWvXTu3atUvXvnfvXtWqVeuOgwIAAO5x+x763125ckXvv/++GjRooPDw8OyICQCAHGEY5m057bYT+qZNm9SjRw8VL15cb775pv75z39q69at2RkbAADIIreG3OPi4jR//nzNmTNHly9fVteuXZWUlKSVK1fyhDsA4K5jy2lr7du3V9WqVbV792698847OnXqlN577z0zYwMAAFmU5Qp97dq1GjhwoF544QVVrlzZzJgAAMgRFirQs16hb968WVeuXFG9evXUsGFDTZkyRefPnzczNgAATJVmGKZtOS3LCf0f//iHZs2apdOnT+u5557TkiVLVKJECaWlpemrr77SlStXzIwTAADchNtPuRcqVEhPP/20Nm/erD179ujf//63JkyYoJCQEHXo0MGMGAEAMAXT1v6/qlWr6o033tDJkye1ePHi7IoJAAC46bbeFPd3Xl5e6tSpkzp16pQd3QEAkCNsOW0NAADkXtlSoQMAcDdKs06BToUOAIAVUKEDAGzLkHVKdBI6AMC2LPRMHEPuAABYARU6AMC2mLYGAAByFSp0AIBtMW0NAADkKlToAADb4h46AADIVajQAQC2ZaECnYQOALCvNAtldIbcAQCwACp0AIBtWahAp0IHAMAKqNABALbFtDUAAJCrUKEDAGzLQgW6dRN6Act+M2Tk2q4png4BOYjrDaRn2bT38+kET4eAHFK9eCH53NPf02Egh1zbNYXrbSNm//FmpXvolk3oAADcioXyOQ/FAQBgBVToAADbstKQOxU6AAAWQIUOALAtKnQAAJCrUKEDAGzLQgU6FToAAFZAQgcA2JZhGKZtWRUVFaV7771Xfn5+CgkJUadOnXTw4EG3vwsJHQBgW4Zh3pZVGzduVL9+/bR161Z99dVXun79ulq2bKmEBPfeeMo9dAAAPOjzzz93+Xn+/PkKCQnRjh071KRJkyz3Q0IHANhWbpy2dunSJUlScHCwW58joQMAYIKkpCQlJSW5tHl7e8vb2zvTz6SlpWnw4MFq3LixatWq5db5uIcOALAtM++hR0VFKSAgwGWLioq6aTz9+vXT3r17tWTJEre/CxU6AAAmiIyM1NChQ13ablad9+/fX6tXr9amTZtUqlQpt89HQgcA2JaZ99BvNbz+1xgGDBigFStWaMOGDSpfvvxtnY+EDgCAB/Xr108ffvihPvnkE/n5+SkuLk6SFBAQIB8fnyz3wz10AIBt5YZ56NOnT9elS5fUrFkzFS9e3LlFR0e79V2o0AEA8KDsGvYnoQMAbCs3zkO/XSR0AIBtWSifcw8dAAAroEIHANiWlYbcqdABALAAKnQAgG1ZqECnQgcAwAqo0AEAtsU9dAAAkKtQoQMAbMtCBToJHQBgXwy5AwCAXIUKHQBgW1ToAAAgV6FCBwDYloUKdCp0AACsgAodAGBb3EMHAAC5ChU6AMC2LFSgk9ABAPaVlmadjM6QOwAAFkCFDgCwLSsNuVOhAwBgAVToAADbYtoaAADIVajQAQC2ZaECnQodAAAroEIHANiWle6hk9ABALZloXzOkDsAAFZAhQ4AsC0rDblToQMAYAFU6AAA26JCBwAAuQoV+l1u8bwZil7wvktbydLlNHXhxx6KCDnhua5NNCTiXypW2F97Dv2moRM/0vZ9xz0dFkzC9TaRdQp0EroVlClXUWPfmu782cvLy4PRwGyPtKyrif/urAHjorVt7zH1f7K5Vk3rp/BOr+rcH/GeDg/ZjOuNrGLI3QLyeHkpqHAR5+YfGOTpkGCigd3/qXkff6+Fq7bqwC9xGjBuia4lJiuiUyNPhwYTcL3NZRiGaVtOI6FbwOnfTqjXwy313BPt9fbr/9G5M6c9HRJMki+vl+6pXlrrfzjobDMMQ+t/OKgGtct7MDKYgettPhI6co0qNcI0cMRYjX5jip4fEqkzp3/TywN769rVBE+HBhMUCfJV3rxeOvv7FZf2sxcuK7Swv4eiglm43nCHxxP6tWvXtHnzZu3fvz/dvsTERH3wwQceiOruUa9hYzVu9qDKVayiexrcp5ET3lNCfLw2f/OVp0MDgFyPCj2bHDp0SNWrV1eTJk0UFhampk2b6vTp/xsuvnTpknr16nXTPpKSknT58mWXLSkpyezQcy1fPz+VKFVGcb/96ulQYILzf8QrJSVVIcF+Lu0hhf0Vd+Gyh6KCWbjecIdHE/rw4cNVq1YtnT17VgcPHpSfn58aN26sEydOZLmPqKgoBQQEuGxRUVEmRp27Xbt6VXGnTiqocBFPhwITXE9J1a6ff1XzhlWdbQ6HQ80bVNGPu2M9GBnMwPU2n5UqdI9OW/v+++/19ddfq0iRIipSpIg+/fRT9e3bVw888IC++eYbFSpU6JZ9REZGaujQoS5t3t7e+uX3FLPCzlXmTZuke+9roqLFiuuPC+e0eN4M5cmTRw/8q7WnQ4NJJv9vvWa9+pR27D+h7f9/GlNBH2998MlWT4cGE3C9kVUeTejXrl1T3rz/F4LD4dD06dPVv39/NW3aVB9++OEt+/D29pa3t3cGe+yR0C+cO6O3XovUlcuXFBAQpOphdTRx2gIFMHXNspZ9uVNFgnw16oV2KlbYT7sP/qaO/aame3AK1sD1Nhkvlske1apV0/bt21W9enWX9ilTpkiSOnTo4Imw7irDRk/wdAjwgBnRmzQjepOnw0AO4XojKzx6D71z585avHhxhvumTJmiJ554wlIvzgcA5C5Wuofu0YQeGRmpzz77LNP906ZNU1paWg5GBACwExI6AADIVVicBQBgW1a6rUuFDgCABVChAwDsyzoFOhU6AABWQIUOALAt7qEDAIBchQodAGBbVqrQSegAANuyUkJnyB0AAAugQgcA2BYVOgAAyFWo0AEA9mWdAp0KHQAAK6BCBwDYFvfQAQBArkKFDgCwLStV6CR0AIBtWSmhM+QOAIAFkNABAPZlmLi5YdOmTWrfvr1KlCghh8OhlStXuv1VSOgAAHhYQkKCwsPDNXXq1Nvug3voAADbyi330Nu0aaM2bdrcUR9U6AAAWAAVOgDAtsys0JOSkpSUlOTS5u3tLW9vb1POR4UOAIAJoqKiFBAQ4LJFRUWZdj4qdACAbZlZoUdGRmro0KEubWZV5xIJHQAAU5g5vJ4REjoAwLZyy1Pu8fHxOnLkiPPn2NhYxcTEKDg4WGXKlMlSHyR0AIB95Y58ru3bt6t58+bOn/8cqo+IiND8+fOz1AcJHQAAD2vWrNkdjxaQ0AEAtpVbhtyzA9PWAACwACp0AIBtUaEDAIBchQodAGBbVOgAACBXoUIHANiWlSp0EjoAwL6sk88ZcgcAwAqo0AEAtmWlIXcqdAAALIAKHQBgW1ToAAAgV6FCBwDYFxU6AADITajQAQD2ZaR5OoJsQ0IHANgXQ+4AACA3oUIHANiXhYbcqdABALAAKnQAgH1xDx0AAOQmVOgAAPviHjoAAMhNqNABAPZloQqdhA4AsC8LPRTnMKy0dpyNJSUlKSoqSpGRkfL29vZ0ODAZ19teuN7m8Wn7rml9X/tskGl9Z4SEbhGXL19WQECALl26JH9/f0+HA5Nxve2F620enzaTTOv72tohpvWdER6KAwDAAriHDgCwLwsNUlOhAwBgAVToFuHt7a3Ro0fzwIxNcL3thettIgtNW+OhOACAbfm0etO0vq99Mcy0vjNChQ4AsC8L1bQkdACAfVloyJ2H4gAAsAASukVMnTpV5cqVU4ECBdSwYUP9+OOPng4JJti0aZPat2+vEiVKyOFwaOXKlZ4OCSaKiorSvffeKz8/P4WEhKhTp046ePCgp8OyFsMwb8thJHQLiI6O1tChQzV69Gjt3LlT4eHhatWqlc6ePevp0JDNEhISFB4erqlTp3o6FOSAjRs3ql+/ftq6dau++uorXb9+XS1btlRCQoKnQ0MuxFPuFtCwYUPde++9mjJliiQpLS1NpUuX1oABAzRixAgPRwezOBwOrVixQp06dfJ0KMgh586dU0hIiDZu3KgmTZp4OhxL8PnXeNP6vrbuZdP6zggV+l0uOTlZO3bsUIsWLZxtefLkUYsWLbRlyxYPRgYgu126dEmSFBwc7OFIkBuR0O9y58+fV2pqqooVK+bSXqxYMcXFxXkoKgDZLS0tTYMHD1bjxo1Vq1YtT4djHRa6h860NQC4C/Tr10979+7V5s2bPR0KcikS+l2uSJEi8vLy0pkzZ1zaz5w5o9DQUA9FBSA79e/fX6tXr9amTZtUqlQpT4djLcxDR26RP39+1atXT+vWrXO2paWlad26dWrUqJEHIwNwpwzDUP/+/bVixQqtX79e5cuX93RI1pNmmLflMCp0Cxg6dKgiIiJUv359NWjQQO+8844SEhLUq1cvT4eGbBYfH68jR444f46NjVVMTIyCg4NVpkwZD0YGM/Tr108ffvihPvnkE/n5+TmfiwkICJCPj4+Ho0Nuw7Q1i5gyZYr++9//Ki4uTnXq1NHkyZPVsGFDT4eFbLZhwwY1b948XXtERITmz5+f8wHBVA6HI8P2efPmqWfPnjkbjEX5NBljWt/XNpnXd0ZI6AAA27JSQmfIHQBgXzwUBwAAchMqdACAfVnorjMVOgAAFkCFDgCwLwvdQyehAwDsiyF3AACQm1ChAwDsy0JD7lTogIl69uypTp06OX9u1qyZBg8enONxbNiwQQ6HQxcvXsz0GIfDoZUrV2a5zzFjxqhOnTp3FNexY8fkcDgUExNzR/0AIKHDhnr27CmHwyGHw6H8+fOrUqVKevXVV5WSkmL6uT/++GO99tprWTo2K0kYwB1iPXTg7ta6dWvNmzdPSUlJ+uyzz9SvXz/ly5dPkZGR6Y5NTk5W/vz5s+W8wcHB2dIPAPwdFTpsydvbW6GhoSpbtqxeeOEFtWjRQqtWrZL0f8Pk48aNU4kSJVS1alVJ0q+//qquXbsqMDBQwcHB6tixo44dO+bsMzU1VUOHDlVgYKAKFy6sl156SX9fKuHvQ+5JSUkaPny4SpcuLW9vb1WqVElz5szRsWPHnIuwBAUFyeFwOBfjSEtLU1RUlMqXLy8fHx+Fh4dr2bJlLuf57LPPVKVKFfn4+Kh58+YucWbV8OHDVaVKFRUsWFAVKlTQyJEjdf369XTHzZw5U6VLl1bBggXVtWtXXbp0yWX/7NmzVb16dRUoUEDVqlXTtGnT3I4FMI2RZt6Ww0jogCQfHx8lJyc7f163bp0OHjyor776SqtXr9b169fVqlUr+fn56dtvv9V3330nX19ftW7d2vm5t956S/Pnz9fcuXO1efNm/f7771qxYsVNz9ujRw8tXrxYkydP1s8//6yZM2fK19dXpUuX1vLlyyVJBw8e1OnTp/Xuu+9KkqKiovTBBx9oxowZ2rdvn4YMGaLu3btr48aNkm784dGlSxe1b99eMTExeuaZZzRixAi3fyd+fn6aP3++9u/fr3fffVezZs3SpEmTXI45cuSIli5dqk8//VSff/65du3apb59+zr3L1q0SKNGjdK4ceP0888/a/z48Ro5cqQWLFjgdjwAbo4hd9iaYRhat26dvvjiCw0YMMDZXqhQIc2ePds51P6///1PaWlpmj17tnNJy3nz5ikwMFAbNmxQy5Yt9c477ygyMlJdunSRJM2YMUNffPFFpuc+dOiQli5dqq+++kotWrSQJFWoUMG5/8/h+ZCQEAUGBkq6UdGPHz9eX3/9tRo1auT8zObNmzVz5kw1bdpU06dPV8WKFfXWW29JkqpWrao9e/Zo4sSJbv1uXnnlFee/y5Urp2HDhmnJkiV66aWXnO2JiYn64IMPVLJkSUnSe++9p3bt2umtt95SaGioRo8erbfeesv5Oylfvrz279+vmTNnKiIiwq14AFNYaB46CR22tHr1avn6+ur69etKS0vTk08+qTFjxjj3h4WFudw3/+mnn3TkyBH5+fm59JOYmKijR4/q0qVLOn36tMsa9Hnz5lX9+vXTDbv/KSYmRl5eXmratGmW4z5y5IiuXr2qBx980KU9OTlZ99xzjyTp559/dolDkjP5uyM6OlqTJ0/W0aNHFR8fr5SUFPn7+7scU6ZMGWcy//M8aWlpOnjwoPz8/HT06FH17t1bffr0cR6TkpKigIAAt+MBTGGhaWskdNhS8+bNNX36dOXPn18lSpRQ3ryu/ykUKlTI5ef4+HjVq1dPixYtStdX0aJFbysGHx8ftz8THx8vSVqzZo1LIpVuPBeQXbZs2aJu3bpp7NixatWqlQICArRkyRJn1e9OrLNmzUr3B4aXl1e2xQrgBhI6bKlQoUKqVKlSlo+vW7euoqOjFRISkq5K/VPx4sX1ww8/qEmTJpJuVKI7duxQ3bp1Mzw+LCxMaWlp2rhxo3PI/a/+HCFITU11ttWoUUPe3t46ceJEppV99erVnQ/4/Wnr1q23/pJ/8f3336ts2bL6z3/+42w7fvx4uuNOnDihU6dOqUSJEs7z5MmTR1WrVlWxYsVUokQJ/fLLL+rWrZtb5wdyjIWG3HkoDsiCbt26qUiRIurYsaO+/fZbxcbGasOGDRo4cKBOnjwpSRo0aJAmTJiglStX6sCBA+rbt+9N55CXK1dOERERevrpp7Vy5Upnn0uXLpUklS1bVg6HQ6tXr9a5c+cUHx8vPz8/DRs2TEOGDNGCBQt09OhR7dy5U++9957zQbPnn39ehw8f1osvvqiDBw/qww8/1Pz58936vpUrV9aJEye0ZMkSHT16VJMnT87wAb8CBQooIiJCP/30k7799lsNHDhQXbt2VWhoqCRp7NixioqK0uTJk3Xo0CHt2bNH8+bN09tvv+1WPABujYQOZEHBggW1adMmlSlTRl26dFH16tXVu3dvJSYmOiv2f//733rqqacUERGhRo0ayc/PT507d75pv9OnT9cjjzyivn37qlq1aurTp48SEhIkSSVLltTYsWM1YsQIFStWTP3795ckvfbaaxo5cqSioqJUvXp1tW7dWmvWrFH58uUl3bivvXz5cq1cuVLh4eGaMWOGxo8f79b37dChg4YMGaL+/furTp06+v777zVy5Mh0x1WqVEldunRR27Zt1bJlS9WuXdtlWtozzzyj2bNna968eQoLC1PTpk01f/58Z6yAx1lo2prDyOyJHQAALM6n3iDT+r624123jp86dar++9//Ki4uTuHh4XrvvffUoEGDLH+eCh0AYF+55NWv0dHRGjp0qEaPHq2dO3cqPDxcrVq10tmzZ7PcBwkdAAAPe/vtt9WnTx/16tVLNWrU0IwZM1SwYEHNnTs3y32Q0AEA9pUL7qEnJydrx44dLrNd8uTJoxYtWmjLli1Z7odpawAAmCApKUlJSUkubd7e3uneGXH+/HmlpqaqWLFiLu3FihXTgQMHsnw+EjoAwLau7ZpiWt9jxozR2LFjXdpGjx7t8lbK7ERCBwDABJGRkRo6dKhLW0ZvdCxSpIi8vLx05swZl/YzZ8443+mQFdxDBwDABN7e3vL393fZMkro+fPnV7169bRu3TpnW1pamtatW+fWOgxU6AAAeNjQoUMVERGh+vXrq0GDBnrnnXeUkJCgXr16ZbkPEjoAAB722GOP6dy5cxo1apTi4uJUp04dff755+kelLsZ3hQHAIAFcA8dAAALIKEDAGABJHQAACyAhA4AgAWQ0AEAsAASOgAAFkBCBwDAAkjoAABYAAkdAAALIKEDAGABJHQAACyAhA4AgAX8P8l40UG1BUxmAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#on colab:\n",
        "#program_path = \"/content/drive/MyDrive/Mestrado/programa_mestrado\"\n",
        "#image_path_train = \"/content/drive/MyDrive/Mestrado/programa_mestrado/imagens/train\"\n",
        "#image_path_val = \"/content/drive/MyDrive/Mestrado/programa_mestrado/imagens/val\"\n",
        "program_path = \".\"\n",
        "image_path_train = \"./images/train\"\n",
        "image_path_val = \"./images/val\"\n",
        "image_path_test = \"./images/test\"\n",
        "\n",
        "# Learning rate for the model\n",
        "lr = 1e-5\n",
        "# Number of training epochs\n",
        "epochs = 2\n",
        "\n",
        "models_to_train = [#['vit_base_patch16_384',384]\n",
        "                    #,['inception_v3',384]\n",
        "                    #,['xception',384]\n",
        "                    #,['vgg16',384]\n",
        "                    #,['vgg19',384]\n",
        "                    #,['visformer_small',224]\n",
        "                    #,['ResNet50',384]\n",
        "                    #,['ResNet101',384]\n",
        "                    #,['densenet121',224]\n",
        "                    #,['densenet169',224]\n",
        "                    #['LeNet',28]\n",
        "                    ['AlexNet',224]\n",
        "                    #['efficientnet_b4',380]\n",
        "                    #['convnext_base',224]\n",
        "                    #['coatnet_2_rw_224.sw_in12k',224]\n",
        "                  ]\n",
        "\n",
        "for i in models_to_train:          \n",
        "    training_class_models(program_path,image_path_train,image_path_val,image_path_test,\\\n",
        "        i[0],lr,epochs,i[1]).initiate()\n",
        "    \n",
        "    #testing the saved models without training phase:\n",
        "    #training_class_models(program_path,image_path_train,image_path_val,image_path_test,\\\n",
        "    #    i[0],lr,epochs,i[1]).test_with_saved_model()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "076f1780a9e44ac8b5f0918f1cb4b87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93e2b4c165da48669fa85bba7ee88dd8",
              "IPY_MODEL_1d41bcdc94624caab1ffc4d2e8c4cc7b",
              "IPY_MODEL_d92e58a73f864ee18eec882d927a8299"
            ],
            "layout": "IPY_MODEL_1319f2732d9741e3936e4f53ad0a643e"
          }
        },
        "10492de5016b460999e9fe3cee9fbb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1319f2732d9741e3936e4f53ad0a643e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d41bcdc94624caab1ffc4d2e8c4cc7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44efa5874cb24d7babed124489cdde0f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac7afb88998e4843a67fb20113e0a1c6",
            "value": 0
          }
        },
        "2132dd337d3348d184c99a7ecf2f166c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3526ad0cb5584bbfaf624969309389ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39398fdfaf734f52b801fba0feb1c6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e60f29667de4495a26844695fea3a81",
            "max": 347452074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dab21b2bb5084dddaab1daf010a31a54",
            "value": 347452074
          }
        },
        "3c3a12e9e4cb424a97d3c0c2a088a412": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44efa5874cb24d7babed124489cdde0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5120b6ab7d224565bace0d12ea3484b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64fd989943b643faa1ddd53c365142ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d74f4eee17424416a46f8f9c835a9681",
            "value": 0
          }
        },
        "558e0cd7f1fe42218d5474c0bfa05c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "629e0b80edc34f028d69938ca23c6ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ae4732fc2c40948a27ce0a1bd33850": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3526ad0cb5584bbfaf624969309389ec",
            "placeholder": "â",
            "style": "IPY_MODEL_d1633f97a3df4b58b2fc03b68239a06e",
            "value": "â0/1â[01:14&lt;?,â?it/s]"
          }
        },
        "64fd989943b643faa1ddd53c365142ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c770ee9b8cc4621be90762fdb5f0625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e60f29667de4495a26844695fea3a81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82b65f9dcd574cac86f2baa1152e2efa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "885d3ecb2a344b7dbe8345af191f78ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e2b4c165da48669fa85bba7ee88dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93f7c34e5c341f1bae3dc5bba397645",
            "placeholder": "â",
            "style": "IPY_MODEL_558e0cd7f1fe42218d5474c0bfa05c3c",
            "value": "Epochs:âââ0%"
          }
        },
        "96ad557a7d0c410a80c5f9f45bd8ed28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2132dd337d3348d184c99a7ecf2f166c",
            "placeholder": "â",
            "style": "IPY_MODEL_3c3a12e9e4cb424a97d3c0c2a088a412",
            "value": "â347M/347Mâ[00:02&lt;00:00,â161MB/s]"
          }
        },
        "96e70b0456b549a2ad3f38f0ff9395fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee107c49bc1f4dfeb8467ecf9baf4420",
              "IPY_MODEL_39398fdfaf734f52b801fba0feb1c6ae",
              "IPY_MODEL_96ad557a7d0c410a80c5f9f45bd8ed28"
            ],
            "layout": "IPY_MODEL_f91f38d8898b4e67a3dacda1c99e391d"
          }
        },
        "ac7afb88998e4843a67fb20113e0a1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4df6842f8ce4bd1bc450bcc18401f41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82cedbc70d84c61b89b1f5a6b77bf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e17ea787578943a5ab471521b3d72bf9",
              "IPY_MODEL_5120b6ab7d224565bace0d12ea3484b6",
              "IPY_MODEL_63ae4732fc2c40948a27ce0a1bd33850"
            ],
            "layout": "IPY_MODEL_885d3ecb2a344b7dbe8345af191f78ed"
          }
        },
        "c93f7c34e5c341f1bae3dc5bba397645": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1633f97a3df4b58b2fc03b68239a06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d74f4eee17424416a46f8f9c835a9681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d92e58a73f864ee18eec882d927a8299": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629e0b80edc34f028d69938ca23c6ad4",
            "placeholder": "â",
            "style": "IPY_MODEL_6c770ee9b8cc4621be90762fdb5f0625",
            "value": "â0/3â[00:45&lt;?,â?it/s]"
          }
        },
        "dab21b2bb5084dddaab1daf010a31a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e17ea787578943a5ab471521b3d72bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4df6842f8ce4bd1bc450bcc18401f41",
            "placeholder": "â",
            "style": "IPY_MODEL_ed1e7ef2cac440f1a1d598ce87f64a18",
            "value": "Train:âââ0%"
          }
        },
        "ed1e7ef2cac440f1a1d598ce87f64a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee107c49bc1f4dfeb8467ecf9baf4420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b65f9dcd574cac86f2baa1152e2efa",
            "placeholder": "â",
            "style": "IPY_MODEL_10492de5016b460999e9fe3cee9fbb35",
            "value": "model.safetensors:â100%"
          }
        },
        "f91f38d8898b4e67a3dacda1c99e391d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
